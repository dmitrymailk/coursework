{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cerf_parsing","provenance":[],"collapsed_sections":[],"mount_file_id":"108aBylbcw0ewoCFDb_9OszFxU-xZj0no","authorship_tag":"ABX9TyMpLm74RTXgMd8g02HXoUL+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"If96dqxsqEit","executionInfo":{"status":"ok","timestamp":1622039224216,"user_tz":-180,"elapsed":1107,"user":{"displayName":"dim web","photoUrl":"","userId":"03939316973290678021"}},"outputId":"447c9f1c-3b3d-4e6d-fde4-279664018698"},"source":["%cd drive/MyDrive/collab_sandbox/cerf_text_classification/\n","!ls"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/collab_sandbox/cerf_text_classification\n","cerf_parsing.ipynb\tdatasets\n","CERF_texts_parsing\tlearnamericanenglishonline_links.csv\n","CERF_texts_parsing.zip\tlearnamericanenglishonline_links.gsheet\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n6Q1Be9bsDqR"},"source":["# !unzip CERF_texts_parsing.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aUkKA76Ls9YI"},"source":["# learnamericanenglishonline"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rx_8Cth3tBoY","executionInfo":{"status":"ok","timestamp":1622039752609,"user_tz":-180,"elapsed":1135,"user":{"displayName":"dim web","photoUrl":"","userId":"03939316973290678021"}},"outputId":"1424b041-3679-4737-cc66-cc243d9dc0ba"},"source":["from bs4 import BeautifulSoup\n","import re\n","import pandas as pd\n","import json\n","import os\n","import requests\n","import pprint \n","\"\"\"\n","A1 => https://www.learnamericanenglishonline.com/Reading/Blue_Level_Reading/Blue_Level_Reading_Room.html\n","A2 => https://www.learnamericanenglishonline.com/Reading/Red_Level_Reading/Red_Level_Reading_Room.html\n","B1 => https://www.learnamericanenglishonline.com/Reading/Yellow_Level_Reading/Yellow_Level_Reading_Room.html\n","B2 => https://www.learnamericanenglishonline.com/Reading/Green_Level_Reading/Green_Level_Reading_Room.html\n","\"\"\"\n","pp = pprint.PrettyPrinter(indent=4)\n","# url = \"https://www.learnamericanenglishonline.com/Reading/Green_Level_Reading/Green_Level_Reading_Room.html\"\n","# page = requests.get(url)\n","# soup = BeautifulSoup(page.content, 'html.parser')\n","# links_list = soup.find(\n","#     'td', attrs={'class': 'bodyText'}).findAll('a', href=True)\n","# bad_chars = [\"../\", 'http']\n","# for item in links_list:\n","#   for char in bad_chars:\n","#     href = str(item['href'])\n","#     cond = sum([int(char in href) for char in bad_chars])\n","#     # print(cond)\n","#     if cond == 0:\n","#       print(href)\n","\n","\n","class ScrapWebsite:\n","    def __init__(self):\n","        self.domain_name = \"https://www.learnamericanenglishonline.com/\"\n","        self.name = 'learnamericanenglishonline'\n","        self.column_names_list = ['link', 'level', 'name']\n","        self.column_names_texts = ['source_text',\n","                                   'level', 'link', 'name', 'metadata']\n","        self.pages_list_urls = {\n","            'A1': [\"https://www.learnamericanenglishonline.com/Reading/Blue_Level_Reading/\", \"Blue_Level_Reading_Room.html\"],\n","            'A2': ['https://www.learnamericanenglishonline.com/Reading/Red_Level_Reading/', \"Red_Level_Reading_Room.html\"],\n","            'B1': [\"https://www.learnamericanenglishonline.com/Reading/Yellow_Level_Reading/\", \"Yellow_Level_Reading_Room.html\"],\n","            'B2': [\"https://www.learnamericanenglishonline.com/Reading/Green_Level_Reading/\", \"Green_Level_Reading_Room.html\"],\n","        }\n","\n","    def parse_pages_urls(self, page_list_url, level):\n","        page = requests.get(page_list_url)\n","        soup = BeautifulSoup(page.content, 'html5lib')\n","\n","        links_list = soup.find('td', attrs={'class': 'bodyText'}).findAll('a', href=True)\n","        bad_chars = [\"../\", 'http']\n","\n","        rows = []\n","        # get hrefs\n","        for item in links_list:\n","          for char in bad_chars:\n","            href = str(item['href'])\n","            cond = sum([int(char in href) for char in bad_chars])\n","            # print(cond)\n","            if cond == 0:\n","              # print(href)\n","\n","              article_link = self.pages_list_urls[level][0] + href\n","              row = {\n","                  'link': article_link,\n","                  'level': level,\n","                  'name': self.name\n","              }\n","              rows.append(row)\n","        return rows\n","\n","    def get_all_links(self):\n","        dataframe = pd.DataFrame(columns=self.column_names_list)\n","\n","        for level, list_url in self.pages_list_urls.items():\n","            list_url = list_url[0] + list_url[1]\n","            # print()\n","            texts_links = self.parse_pages_urls(list_url, level)\n","            for item in texts_links:\n","                dataframe = dataframe.append(item, ignore_index=True)\n","\n","        dataframe.to_csv(f\"{self.name}_links.csv\", index=False)\n","        print('OK. Links parsed.')\n","\n","    def get_all_texts(self):\n","        dataframe_links = pd.read_csv(\"continuingstudies_links.csv\")\n","        dataframe_texts = pd.DataFrame(columns=self.column_names_texts)\n","        data_len = len(dataframe_links)\n","        for i in range(data_len):\n","            # print(row)\n","            row = dataframe_links.iloc[i]\n","            level = row['level']\n","            link = row['link']\n","            new_row = self.scrap_one_page(link, level)\n","            dataframe_texts = dataframe_texts.append(\n","                new_row, ignore_index=True)\n","        dataframe_texts.to_csv(f'{self.name}_texts.csv', index=False)\n","        print('OK. Texts Parsed.')\n","\n","    def scrap_one_page(self, url, level):\n","        page = requests.get(url)\n","        soup = BeautifulSoup(page.content, 'html.parser')\n","        title = soup.find('td', attrs={'class': 'pageName'})\n","        title = title.getText()\n","        page = soup.find('article')\n","        # text, audio_link = self.remove_trash(text)\n","        print(str(page))\n","        # print(page)\n","        # row = {\n","        #     'level': level,\n","        #     'source_text': text,\n","        #     'link': url,\n","        #     'name': self.name,\n","        #     'metadata': \"{'audio_link': %s}\" % audio_link\n","        # }\n","        return page\n","\n","    def remove_trash(self, text=None):\n","        new_text = str(text)\n","        regex_array = [\n","            r\"<sup><strong>.<\\/strong><\\/sup>\",\n","            r\"(<([^>]+)>)\",\n","            r\"Your browser does not support the audio element, so here's a link to the mp3:\",\n","            r\"[’”“]\",\n","            r\"\\n\",\n","            r\"(Credits:.*)\"\n","        ]\n","        for regex_str in regex_array:\n","            search_line = re.compile(regex_str)\n","            new_text = search_line.sub(\"\", new_text).strip()\n","\n","        audio_link = \"\"\n","        search_line = re.compile(r\"(https.*\\.mp3)\")\n","        new_audio_link = search_line.findall(new_text)\n","        if len(new_audio_link) > 0:\n","            audio_link = new_audio_link[0]\n","        new_text = search_line.sub(\"\", new_text).strip()\n","\n","        return new_text, audio_link\n","\n","\n","if __name__ == '__main__':\n","  site_scrapper = ScrapWebsite()\n","  # site_scrapper.get_all_links()\n","\t# site_scrapper.get_all_texts()\n","  link = \"https://www.learnamericanenglishonline.com/Reading/Blue_Level_Reading/6_Jacob_and_Matt_are_studying.html\"\n","\n","site_scrapper.scrap_one_page(link, \"a1\")\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["<article class=\"post-1419 page type-page status-publish\" id=\"post-1419\" itemscope=\"\" itemtype=\"https://schema.org/CreativeWork\"><div class=\"inside-article\"><div class=\"entry-content\" itemprop=\"text\"><table border=\"0\" cellpadding=\"2\" cellspacing=\"0\" class=\"table\"><tr><td class=\"pageName\" colspan=\"3\">6. Jacob and Matt are studying English online together.</td></tr><tr><td class=\"subHeader\"></td></tr></table></div></div></article>\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<article class=\"post-1419 page type-page status-publish\" id=\"post-1419\" itemscope=\"\" itemtype=\"https://schema.org/CreativeWork\"><div class=\"inside-article\"><div class=\"entry-content\" itemprop=\"text\"><table border=\"0\" cellpadding=\"2\" cellspacing=\"0\" class=\"table\"><tr><td class=\"pageName\" colspan=\"3\">6. Jacob and Matt are studying English online together.</td></tr><tr><td class=\"subHeader\"></td></tr></table></div></div></article>"]},"metadata":{"tags":[]},"execution_count":10}]}]}