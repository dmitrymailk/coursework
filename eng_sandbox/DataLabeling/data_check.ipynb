{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSES_LIST = {\n",
    "\"a1_be_have_do_in_the_past\": 23,\n",
    "\"a1_can\": 14,\n",
    "\"a1_comparative_exept\": 4,\n",
    "\"a1_comparative_long\": 3,\n",
    "\"a1_comparative_short\": 2,\n",
    "\"a1_future_simple\": 20,\n",
    "\"a1_have_has_got\": 22,\n",
    "\"a1_past_simple_irreg\": 19,\n",
    "\"a1_past_simple_reg\": 18,\n",
    "\"a1_possesive_s_sing\": 0,\n",
    "\"a1_possessive_s_plurar\": 1,\n",
    "\"a1_present_continuous_act_rn\": 17,\n",
    "\"a1_present_simple_3d_pers\": 16,\n",
    "\"a1_present_simple_reg_act\": 15,\n",
    "\"a1_special_questions\": 24,\n",
    "\"a1_superlative_exept\": 7,\n",
    "\"a1_superlative_long\": 6,\n",
    "\"a1_superlative_short\": 5,\n",
    "\"a1_there_is_am_are\": 12,\n",
    "\"a1_there_was_were\": 11,\n",
    "\"a1_there_will_be\": 13,\n",
    "\"a1_to_be_future_will_be\": 10,\n",
    "\"a1_to_be_past_was_were\": 8,\n",
    "\"a1_to_be_present_is_am_are\": 9,\n",
    "\"a1_want_would_like_to\": 21,\n",
    "\"a2_adjectives_ed\": 46,\n",
    "\"a2_adjectives_ing\": 45,\n",
    "\"a2_ask_reported_verb\": 57,\n",
    "\"a2_could\": 25,\n",
    "\"a2_first_conditional_if_m\": 66,\n",
    "\"a2_first_conditional_m_if\": 67,\n",
    "\"a2_had_to\": 31,\n",
    "\"a2_have_to\": 30,\n",
    "\"a2_imp_reported_speech\": 54,\n",
    "\"a2_imperatives\": 35,\n",
    "\"a2_ing_non_finite_forms\": 50,\n",
    "\"a2_is_able_to\": 27,\n",
    "\"a2_is_am_are_going_to\": 37,\n",
    "\"a2_much_many_a_lot\": 43,\n",
    "\"a2_must\": 29,\n",
    "\"a2_narrative_tenses\": 40,\n",
    "\"a2_passive_modal_verbs\": 63,\n",
    "\"a2_passive_past_simple\": 61,\n",
    "\"a2_passive_present_cont\": 59,\n",
    "\"a2_passive_present_perf\": 60,\n",
    "\"a2_passive_present_simple\": 58,\n",
    "\"a2_passive_will\": 62,\n",
    "\"a2_past_continuous\": 39,\n",
    "\"a2_past_perfect_basic\": 42,\n",
    "\"a2_past_reported_speech\": 53,\n",
    "\"a2_pr_reported_speech\": 52,\n",
    "\"a2_prepositions_of_time\": 34,\n",
    "\"a2_present_perfect\": 41,\n",
    "\"a2_relative_clause_others\": 47,\n",
    "\"a2_relative_clause_who_which_that\": 48,\n",
    "\"a2_say_reported_verb\": 55,\n",
    "\"a2_second_conditional_if_m\": 68,\n",
    "\"a2_second_conditional_m_if\": 69,\n",
    "\"a2_should\": 33,\n",
    "\"a2_tell_reported_verb\": 56,\n",
    "\"a2_to_non_finite_forms\": 49,\n",
    "\"a2_was_were_be_able_to\": 26,\n",
    "\"a2_was_were_going_to\": 36,\n",
    "\"a2_will_be_able_to\": 28,\n",
    "\"a2_will_be_going_to\": 38,\n",
    "\"a2_will_have_to\": 32,\n",
    "\"a2_zero_article\": 44,\n",
    "\"a2_zero_conditional_if_m\": 64,\n",
    "\"a2_zero_conditional_m_if\": 65,\n",
    "\"a2_zero_non_finite_forms\": 51,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_dataset(dataset):\r\n",
    "    new_dataset = dataset\r\n",
    "    new_dataset = new_dataset[['Labeled Data', 'Label', 'View Label']]\r\n",
    "    new_dataset['labels'] = 0\r\n",
    "    for i in range(len(new_dataset)):\r\n",
    "        answers = json.loads(new_dataset['Label'][i])\r\n",
    "        answers = answers.get('classifications', 0)\r\n",
    "        if answers != 0:\r\n",
    "            # answers = answers]\r\n",
    "            if len(answers) > 0:\r\n",
    "                answers = answers[0]['answers']\r\n",
    "                labels = [item['value'] for item in answers]\r\n",
    "                new_dataset['labels'][i] = labels\r\n",
    "                # print(labels)\r\n",
    "    new_dataset = new_dataset[['Labeled Data', 'labels', 'View Label']]\r\n",
    "    new_dataset = new_dataset[new_dataset['labels'] != 0 & (new_dataset['Labeled Data'].duplicated() == False)]\r\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_text(dirty_text):\n",
    "    bad_chars = {\n",
    "        \"’\":\"'\",\n",
    "        \"‘\": \"'\",\n",
    "        \"“\": ' ',\n",
    "        \"”\": ' ',\n",
    "        \"—\": \"-\",\n",
    "        \"…\": \"...\",\n",
    "        \"–\": \"-\",\n",
    "        '\"': \" \",\n",
    "        '[': \"\",\n",
    "        \"]\": \"\",\n",
    "        '(Laughter)': ' ',\n",
    "        '(Applause)': ' ',\n",
    "        '--': '-',\n",
    "        \"&gt;\": ''\n",
    "    }\n",
    "    new_text = str(dirty_text).strip()\n",
    "    for bad_char in bad_chars:\n",
    "        new_text = new_text.replace(bad_char, bad_chars[bad_char])\n",
    "                \n",
    "    _replace_whitespace_ = re.compile(r\"\\s+\")\n",
    "    new_text = _replace_whitespace_.sub(\" \", new_text).strip()\n",
    "\n",
    "    _replace_multiple_whitespaces = re.compile(r'\\s{1,}')\n",
    "    new_text = _replace_multiple_whitespaces.sub(\" \", new_text).strip()\n",
    "\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Labeled Data</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>",
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Labeled Data, labels]\n",
       "Index: []"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_1 = pd.read_csv('export-2021-02-04T12_04_07.333Z.csv', encoding='utf-8')\n",
    "dataset_1 = convert_dataset(dataset_1)\n",
    "dataset_1[dataset_1['Labeled Data'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_300 = pd.read_csv('./multi_label_tenses/300.csv', encoding='utf-8')\r\n",
    "# dataset_300 = convert_dataset(dataset_300)\r\n",
    "# dataset_300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1207\n"
     ]
    }
   ],
   "source": [
    "dataset_ner_pred = pd.read_csv(\"./combine_data/combine_2_21_21_NER/predicted_tenses_2_16_21_NER_1207_balanced_a1_tokenized.csv\")\r\n",
    "dataset_ner_pred['source'] = 0\r\n",
    "dataset_ner_pred['dup'] = 0\r\n",
    "\r\n",
    "dataset_ner_labeled = pd.read_csv(\"./combine_data/combine_2_21_21_NER/export-2021-02-19T15_38_59.685Z.csv\")\r\n",
    "dataset_ner_labeled = dataset_ner_labeled[['Labeled Data']]\r\n",
    "dataset_ner_labeled = dataset_ner_labeled.rename(columns={'Labeled Data': 'sent'})\r\n",
    "dataset_ner_labeled['type'] = \"\"\r\n",
    "dataset_ner_labeled['original_sent'] = \"\"\r\n",
    "dataset_ner_labeled['source'] = 1\r\n",
    "dataset_ner_labeled['dup'] = 0\r\n",
    "\r\n",
    "print(len(dataset_ner_pred))\r\n",
    "\r\n",
    "dataset_ner_pred_labeled_comb = pd.concat([dataset_ner_pred, dataset_ner_labeled], ignore_index=True)\r\n",
    "\r\n",
    "for i in range(len(dataset_ner_labeled)):\r\n",
    "  sent = dataset_ner_labeled['sent'][i]\r\n",
    "  dataset_ner_pred_labeled_comb['dup'][dataset_ner_pred_labeled_comb['sent'] == str(sent)] = 1\r\n",
    "dataset_ner_pred_labeled_comb = dataset_ner_pred_labeled_comb[dataset_ner_pred_labeled_comb['dup'] == 0]\r\n",
    "dataset_ner_pred_labeled_comb = dataset_ner_pred_labeled_comb[['sent', 'original_sent']]\r\n",
    "dataset_ner_pred_labeled_comb.to_csv(\"./combine_data/combine_2_21_21_NER/dataset_ner_pred_labeled_comb_2_21_21.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_label_tenses = pd.concat([dataset_1])\n",
    "multi_label_tenses = multi_label_tenses.rename(columns={'Labeled Data': 'sent', 'labels':'type'})\n",
    "multi_label_tenses.to_csv(\"syntetic_dataset_labeled_2_4_21_a1_labeled.csv\", index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_stat = pd.read_csv(\"./combine_data/combined_04_02_2021.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sent</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I have never once washed an apple from the sto...</td>\n      <td>['a2_present_perfect', 'a1_past_simple_irreg',...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Under the rules of dueling, Dickinson had to r...</td>\n      <td>['a2_had_to', 'a1_past_simple_irreg', 'a2_narr...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Usually, when I tell someone, they give me a b...</td>\n      <td>['a2_first_conditional_if_m', 'a1_present_simp...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Unfortunately, the names of the developer comm...</td>\n      <td>['a2_article_the', 'a1_to_be_present_is_am_are...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>We recommend you use a developer command promp...</td>\n      <td>['a1_possessive_pronouns']</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": [
       "                                                sent  \\\n",
       "0  I have never once washed an apple from the sto...   \n",
       "1  Under the rules of dueling, Dickinson had to r...   \n",
       "2  Usually, when I tell someone, they give me a b...   \n",
       "3  Unfortunately, the names of the developer comm...   \n",
       "4  We recommend you use a developer command promp...   \n",
       "\n",
       "                                                type  \n",
       "0  ['a2_present_perfect', 'a1_past_simple_irreg',...  \n",
       "1  ['a2_had_to', 'a1_past_simple_irreg', 'a2_narr...  \n",
       "2  ['a2_first_conditional_if_m', 'a1_present_simp...  \n",
       "3  ['a2_article_the', 'a1_to_be_present_is_am_are...  \n",
       "4                         ['a1_possessive_pronouns']  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_stat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSES_LIST_NAMES =  list(TENSES_LIST.keys())\n",
    "# for i in TENSES_LIST_NAMES:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_stat[list(TENSES_LIST.keys())] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_stat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_1200['a2_article_a_an']\n",
    "# TENSES_LIST_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_dataset(dataset):\n",
    "    new_dataset = dataset\n",
    "    for i in range(len(dataset)): \n",
    "        sent_types = str(dataset['type'][i])\n",
    "        sent_types = json.loads(sent_types.replace(\"'\",'\"'))\n",
    "        # print(sent_types)\n",
    "        # sent_types = [TENSES_LIST.get(typ) for typ in sent_types if TENSES_LIST.get(typ, -1) != -1]\n",
    "        # print(sent_types)\n",
    "        if len(sent_types) != 0:\n",
    "            for label in sent_types:\n",
    "                if label in TENSES_LIST_NAMES:\n",
    "                    new_dataset[label][i] = 1\n",
    "        \n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_stat = conv_dataset(dataset_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_1200.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1200.to_csv(\"1200_dataframe_1_29_20.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2_adjectives_ing\n",
      "a2_ask_reported_verb\n",
      "a2_first_conditional_m_if\n",
      "a2_have_to\n",
      "a2_imp_reported_speech\n",
      "a2_is_able_to\n",
      "a2_must\n",
      "a2_passive_present_cont\n",
      "a2_passive_present_perf\n",
      "a2_past_reported_speech\n",
      "a2_pr_reported_speech\n",
      "a2_prepositions_of_time\n",
      "a2_second_conditional_if_m\n",
      "a2_second_conditional_m_if\n",
      "a2_tell_reported_verb\n",
      "a2_was_were_be_able_to\n",
      "a2_was_were_going_to\n",
      "a2_will_be_able_to\n",
      "a2_will_be_going_to\n",
      "a2_will_have_to\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "minor_classes = []\n",
    "for label in TENSES_LIST_NAMES:\n",
    "    lenght = len(dataset_stat[dataset_stat[label] == 1])\n",
    "    # print(f\"{label} --- {lenght}\")\n",
    "    if lenght < 10:\n",
    "        print(label)\n",
    "        minor_classes.append(label)\n",
    "        total += 1\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While I found Weather Channel's Bus Shelter prank amusing, others might be frustrated for getting wet in what they will later regard as a stupid prank.\n",
      "It has to do with a broad, consistent logic, and that logic could be understood as one occupies the building.\n",
      "Devices that can be made in PolyMUMPs include: Acoustics(microphones), Sensors, Accelerometers, Micro-fluidics, and Display Technologies.\n",
      "We want to have a community where you can upload ideas, and those ideas can be tested in an earthquake, in flood, in all sorts of austere environments.\n",
      "Time blocking can be wise if you use it appropriately and if you ease into it.\n",
      "It is a beautiful and terrible thing, and should therefore be treated with great caution.\n",
      "Tight schedules with no flexibility can be overwhelming and feeling like you didn't accomplish a certain goal can be taxing to your mental health.\n",
      "However, mild competition can be healthy and in fact, a necessary source of inspiration.\n",
      "The study acknowledges that the anxiety that individuals have in marriages based on their economic dependence or independence might be affected by their prior views about traditional gender roles.\n",
      "The Czech side believes that at least part of the debt should be dealt in cash, it said.\n",
      "Rules are normally contained on a single line; rules with many alternatives may be formatted alternatively with each line after the first beginning with a vertical bar.\n",
      "From the ease with which you swept away obstacles that no one knew could even be budged.\n",
      "Since it must be assumed that Comey is no fool, it must also be assumed that he knew what he was doing.\n",
      "They have even said that those like ISIS can no longer even be considered Muslims.\n"
     ]
    }
   ],
   "source": [
    "# sample = dataset_1200[dataset_1200['a2_passive_modal_verbs'] == 1]['sent'].sample(frac=1)[:20]\n",
    "# sa\n",
    "# for i in range(len(sample)):\n",
    "#     print(sample.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntetic_dataset = pd.DataFrame(columns=minor_classes)\n",
    "syntetic_dataset.to_csv(\"syntetic_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntetic_dataset_labeled_2_4_21_a1 = pd.read_csv(\"syntetic_dataset_labeled_2_4_21_a1.csv\", encoding='utf-8')\n",
    "syntetic_dataset_labeled_2_4_21_a1_transformed = pd.DataFrame(columns=['sent', 'type'])\n",
    "\n",
    "for column in list(syntetic_dataset_labeled_2_4_21_a1.columns):\n",
    "    column_sents = syntetic_dataset_labeled_2_4_21_a1[column]\n",
    "    for sent in column_sents:\n",
    "        row = {}\n",
    "        row['sent'] = pretty_text(str(sent))\n",
    "        row['type'] = str(column)\n",
    "        syntetic_dataset_labeled_2_4_21_a1_transformed = syntetic_dataset_labeled_2_4_21_a1_transformed.append(row, ignore_index=True)\n",
    "\n",
    "syntetic_dataset_labeled_2_4_21_a1_transformed = syntetic_dataset_labeled_2_4_21_a1_transformed[syntetic_dataset_labeled_2_4_21_a1_transformed['sent'].duplicated() == False]\n",
    "syntetic_dataset_labeled_2_4_21_a1_transformed.to_csv(\"syntetic_dataset_labeled_2_4_21_a1_transformed.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check dublicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sent</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>",
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sent, type]\n",
       "Index: []"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntetic_dataset_labeled_2_4_21_a1_transformed = pd.read_csv('syntetic_dataset_labeled_2_4_21_a1_transformed.csv')\n",
    "syntetic_dataset_labeled_2_4_21_a1_transformed[syntetic_dataset_labeled_2_4_21_a1_transformed['sent'].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on previous dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_dataset = pd.read_csv(\"./combine_data/combined_29_01_2021.csv\")\n",
    "current_dataset = pd.read_csv(\"syntetic_dataset_labeled_2_4_21_a1_transformed.csv\")\n",
    "prev_current_dataset = pd.concat([prev_dataset, current_dataset])\n",
    "prev_current_dataset[prev_current_dataset.duplicated()]\n",
    "temp = prev_current_dataset\n",
    "temp.to_csv('temp.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('ai-env')",
   "metadata": {
    "interpreter": {
     "hash": "ee89ffdf677b068b3969c9c92fc557abd8fe9bdccee3c1b3432324df722c1402"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}