{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('ai-env')",
   "metadata": {
    "interpreter": {
     "hash": "ee89ffdf677b068b3969c9c92fc557abd8fe9bdccee3c1b3432324df722c1402"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Bert for Multilabel Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2305df88c10>"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "SEED = 10\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_1 = pd.read_csv('../synth-data.csv', encoding='utf-8')\n",
    "# dataset_1 = dataset_1.drop([\"affirmative\",\"negative\",\"question\"], axis=1)\n",
    "# dataset_1 = dataset_1[(dataset_1['type'] != 'trash')\n",
    "#                      &\n",
    "#                      (dataset_1['type'] != 'other')]\n",
    "\n",
    "# dataset_2 = pd.read_csv('../ted-label.csv', encoding='utf-8')\n",
    "# dataset_2 = dataset_2.drop([\"predicted_type\",\"data_trash\",\"sentence_id\",\"date\"], axis=1)\n",
    "# dataset_2 = dataset_2[(dataset_2['actual_type'] != 'trash')\n",
    "#                      &\n",
    "#                      (dataset_2['actual_type'] != 'other')\n",
    "#                      ]\n",
    "\n",
    "# dataset_1 = dataset_1.rename(columns={'sentences': 'sent'})\n",
    "# dataset_2 = dataset_2.rename(columns={'sentence': 'sent', 'actual_type': 'type'})\n",
    "# dataset = pd.concat([dataset_1, dataset_2])\n",
    "# dataset.to_csv(\"multi-all-sents.csv\", encoding='utf-8', index=False)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENT_TYPES = {'present_continuous': 0,\n",
    "#             'to_be_future': 1,\n",
    "#             'past_continuous': 2,\n",
    "#             'past_simple': 3,\n",
    "#             'can': 4,\n",
    "#             'future_simple': 5,\n",
    "#             'to_be_present': 6,\n",
    "#             'used_to': 7,\n",
    "#             'to_be_past': 8,\n",
    "#             'present_simple': 9,\n",
    "#             'other': 10,\n",
    "#             'present_perfect': 11,\n",
    "#             'could': 12}\n",
    "# SENT_TYPES = {'present_continuous': 0,\n",
    "#             'to_be_future': 1,\n",
    "#             'past_continuous': 2,\n",
    "#             'past_simple': 3,\n",
    "#             'can': 4,\n",
    "#             'future_simple': 5,\n",
    "#             'to_be_present': 6,\n",
    "#             'used_to': 7,\n",
    "#             'to_be_past': 8,\n",
    "#             'present_simple': 9,\n",
    "#             'present_perfect': 10,\n",
    "#             'could': 11}\n",
    "\n",
    "SENT_TYPES = {\n",
    "\"a1_be_have_do_in_the_past\": 23,\n",
    "\"a1_can\": 14,\n",
    "\"a1_comparative_exept\": 4,\n",
    "\"a1_comparative_long\": 3,\n",
    "\"a1_comparative_short\": 2,\n",
    "\"a1_future_simple\": 20,\n",
    "\"a1_have_has_got\": 22,\n",
    "\"a1_past_simple_irreg\": 19,\n",
    "\"a1_past_simple_reg\": 18,\n",
    "\"a1_possesive_s_sing\": 0,\n",
    "\"a1_possessive_s_plurar\": 1,\n",
    "\"a1_present_continuous_act_rn\": 17,\n",
    "\"a1_present_simple_3d_pers\": 16,\n",
    "\"a1_present_simple_reg_act\": 15,\n",
    "\"a1_special_questions\": 24,\n",
    "\"a1_superlative_exept\": 7,\n",
    "\"a1_superlative_long\": 6,\n",
    "\"a1_superlative_short\": 5,\n",
    "\"a1_there_is_am_are\": 12,\n",
    "\"a1_there_was_were\": 11,\n",
    "\"a1_there_will_be\": 13,\n",
    "\"a1_to_be_future_will_be\": 10,\n",
    "\"a1_to_be_past_was_were\": 8,\n",
    "\"a1_to_be_present_is_am_are\": 9,\n",
    "\"a1_want_would_like_to\": 21,\n",
    "\"a2_adjectives_ed\": 46,\n",
    "\"a2_adjectives_ing\": 45,\n",
    "\"a2_ask_reported_verb\": 57,\n",
    "\"a2_could\": 25,\n",
    "\"a2_first_conditional_if_m\": 66,\n",
    "\"a2_first_conditional_m_if\": 67,\n",
    "\"a2_had_to\": 31,\n",
    "\"a2_have_to\": 30,\n",
    "\"a2_imp_reported_speech\": 54,\n",
    "\"a2_imperatives\": 35,\n",
    "\"a2_ing_non_finite_forms\": 50,\n",
    "\"a2_is_able_to\": 27,\n",
    "\"a2_is_am_are_going_to\": 37,\n",
    "\"a2_much_many_a_lot\": 43,\n",
    "\"a2_must\": 29,\n",
    "\"a2_narrative_tenses\": 40,\n",
    "\"a2_passive_modal_verbs\": 63,\n",
    "\"a2_passive_past_simple\": 61,\n",
    "\"a2_passive_present_cont\": 59,\n",
    "\"a2_passive_present_perf\": 60,\n",
    "\"a2_passive_present_simple\": 58,\n",
    "\"a2_passive_will\": 62,\n",
    "\"a2_past_continuous\": 39,\n",
    "\"a2_past_perfect_basic\": 42,\n",
    "\"a2_past_reported_speech\": 53,\n",
    "\"a2_pr_reported_speech\": 52,\n",
    "\"a2_prepositions_of_time\": 34,\n",
    "\"a2_present_perfect\": 41,\n",
    "\"a2_relative_clause_others\": 47,\n",
    "\"a2_relative_clause_who_which_that\": 48,\n",
    "\"a2_say_reported_verb\": 55,\n",
    "\"a2_second_conditional_if_m\": 68,\n",
    "\"a2_second_conditional_m_if\": 69,\n",
    "\"a2_should\": 33,\n",
    "\"a2_tell_reported_verb\": 56,\n",
    "\"a2_to_non_finite_forms\": 49,\n",
    "\"a2_was_were_be_able_to\": 26,\n",
    "\"a2_was_were_going_to\": 36,\n",
    "\"a2_will_be_able_to\": 28,\n",
    "\"a2_will_be_going_to\": 38,\n",
    "\"a2_will_have_to\": 32,\n",
    "\"a2_zero_article\": 44,\n",
    "\"a2_zero_conditional_if_m\": 64,\n",
    "\"a2_zero_conditional_m_if\": 65,\n",
    "\"a2_zero_non_finite_forms\": 51,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "np.zeros((len(SENT_TYPES), ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_type_to_categories(dataframe, SENT_TYPES=SENT_TYPES):\n",
    "    for i in range(len(dataframe['type'])):\n",
    "        sent_type = str(dataframe['type'][i])\n",
    "        arr = np.zeros((len(SENT_TYPES)), dtype=\"int\")\n",
    "        # print(arr[0])\n",
    "        arr[SENT_TYPES[sent_type]] = 1\n",
    "        dataframe['type'][i] = arr\n",
    "        break\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"['a2_present_perfect', 'a1_past_simple_irreg', 'a2_narrative_tenses', 'a2_article_a_an', 'a1_singular_nouns']\"",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-565994a2e868>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_type_to_categories\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"multi_label_tenses.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-7c0cea5c7b1c>\u001b[0m in \u001b[0;36mconvert_type_to_categories\u001b[1;34m(dataframe, SENT_TYPES)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSENT_TYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"int\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m# print(arr[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSENT_TYPES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msent_type\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['a2_present_perfect', 'a1_past_simple_irreg', 'a2_narrative_tenses', 'a2_article_a_an', 'a1_singular_nouns']\""
     ]
    }
   ],
   "source": [
    "dataset = convert_type_to_categories(pd.read_csv(\"multi_label_tenses.csv\"))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "source": [
    "dataset['type'][0]"
   ]
  },
  {
   "source": [
    "# Split Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from catalyst.utils import set_global_seed\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'data': {\n",
    "        'text_field_name': 'sent',\n",
    "        'label_field_name': 'type',\n",
    "        'path_to_dataset': 'all-sents.csv',\n",
    "        'path_to_test_pred_scores': 'data/pred.txt'\n",
    "    },\n",
    "    'model': {\n",
    "        'max_seq_length': 128,\n",
    "        'model_name': 'distilbert-base-uncased',\n",
    "        'num_classes': 12\n",
    "    },\n",
    "    'training': {\n",
    "        'learn_rate': 3e-5,\n",
    "        'num_epochs': 3,                          \n",
    "        'accum_steps': 2,                         \n",
    "        'batch_size': 2,\n",
    "        'trashhold': 0.75,                         \n",
    "        'log_dir': 'logdir' \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(params, dataset):\n",
    "    # dataset = pd.read_csv(params['data']['path_to_dataset'], encoding='utf-8')\n",
    "    dataset = dataset.sample(frac=1)\n",
    "    train, valid, test = np.split(dataset, \n",
    "               [int(.8*len(dataset)), int(.9*len(dataset))])\n",
    "    # print(train.head())\n",
    "    test.to_csv('mul-test.csv', encoding='utf-8', index=False)\n",
    "    # creating PyTorch Datasets\n",
    "    train_dataset = TextClassificationDataset(\n",
    "        texts=train[params[\"data\"][\"text_field_name\"]].values.tolist(),\n",
    "        labels=train[params[\"data\"][\"label_field_name\"]].values,\n",
    "        max_seq_length=params[\"model\"][\"max_seq_length\"],\n",
    "        model_name=params[\"model\"][\"model_name\"],\n",
    "    )\n",
    "\n",
    "    valid_dataset = TextClassificationDataset(\n",
    "        texts=valid[params[\"data\"][\"text_field_name\"]].values.tolist(),\n",
    "        labels=valid[params[\"data\"][\"label_field_name\"]].values,\n",
    "        max_seq_length=params[\"model\"][\"max_seq_length\"],\n",
    "        model_name=params[\"model\"][\"model_name\"],\n",
    "    )\n",
    "\n",
    "    test_dataset = TextClassificationDataset(\n",
    "        texts=test[params[\"data\"][\"text_field_name\"]].values.tolist(),\n",
    "        labels=test[params[\"data\"][\"label_field_name\"]].values,\n",
    "        max_seq_length=params[\"model\"][\"max_seq_length\"],\n",
    "        model_name=params[\"model\"][\"model_name\"],\n",
    "    )\n",
    "\n",
    "    set_global_seed(SEED)\n",
    "\n",
    "    # creating PyTorch data loaders and placing them in dictionaries (for Catalyst)\n",
    "    train_val_loaders = {\n",
    "        \"train\": DataLoader(\n",
    "            dataset=train_dataset,\n",
    "            batch_size=params[\"training\"][\"batch_size\"],\n",
    "            shuffle=True,\n",
    "        ),\n",
    "        \"valid\": DataLoader(\n",
    "            dataset=valid_dataset,\n",
    "            batch_size=params[\"training\"][\"batch_size\"],\n",
    "            shuffle=False,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    test_loaders = {\n",
    "        \"test\": DataLoader(\n",
    "            dataset=test_dataset,\n",
    "            batch_size=params[\"training\"][\"batch_size\"],\n",
    "            shuffle=False,\n",
    "        )\n",
    "    }\n",
    "\n",
    "    return train_val_loaders, test_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        texts,\n",
    "        labels = None,\n",
    "        # label_dict = None,\n",
    "        max_seq_length = 128,\n",
    "        model_name = \"distilbert-base-uncased\",\n",
    "    ):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        # self.label_dict = label_dict\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "        # if self.label_dict is None and labels is not None:\n",
    "        #     # {'class1': 0, 'class2': 1, 'class3': 2, ...}\n",
    "        #     # using this instead of `sklearn.preprocessing.LabelEncoder`\n",
    "        #     # no easily handle unknown target values\n",
    "        #     self.label_dict = dict(zip(sorted(set(labels)), range(len(set(labels)))))\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        # suppresses tokenizer warnings\n",
    "        logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.FATAL)\n",
    "\n",
    "        \n",
    "        self.sep_vid = self.tokenizer.vocab[\"[SEP]\"]\n",
    "        self.cls_vid = self.tokenizer.vocab[\"[CLS]\"]\n",
    "        self.pad_vid = self.tokenizer.vocab[\"[PAD]\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # encoding the text\n",
    "        x = self.texts[index]\n",
    "\n",
    "        # a dictionary with `input_ids` and `attention_mask` as keys\n",
    "        output_dict = self.tokenizer.encode_plus(\n",
    "            x,\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_seq_length,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "\n",
    "        # for Catalyst, there needs to be a key called features\n",
    "        output_dict[\"features\"] = output_dict[\"input_ids\"].squeeze(0)\n",
    "        del output_dict[\"input_ids\"]\n",
    "\n",
    "        # encoding target\n",
    "        if self.labels is not None:\n",
    "            y = self.labels[index]\n",
    "            # y_encoded = torch.Tensor([self.label_dict.get(y, -1)]).long().squeeze(0)\n",
    "            y_encoded = torch.tensor(y, dtype=torch.float32).squeeze(0)\n",
    "            output_dict[\"targets\"] = y_encoded\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "torch.tensor(np.array(np.zeros((3), dtype='float32')), dtype=torch.float32).squeeze(0)"
   ]
  },
  {
   "source": [
    "# Bert Model Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForSequenceClassification(nn.Module):\n",
    "    \"\"\"\n",
    "    Simplified version of the same class by HuggingFace.\n",
    "    See transformers/modeling_distilbert.py in the transformers repository.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, pretrained_model_name, num_classes = None, dropout = 0.3\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        config = AutoConfig.from_pretrained(\n",
    "            pretrained_model_name, num_labels=num_classes\n",
    "        )\n",
    "\n",
    "        self.model = AutoModel.from_pretrained(pretrained_model_name, config=config)\n",
    "        # self.classifier = nn.Linear(config.hidden_size, num_classes)\n",
    "        # self.dropout = nn.Dropout(dropout)\n",
    "        self.pre_classifier = nn.Linear(config.dim, config.dim)\n",
    "        self.classifier = nn.Linear(config.dim, num_classes)\n",
    "        self.dropout = nn.Dropout(config.seq_classif_dropout)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, features, attention_mask=None, head_mask=None):\n",
    "        \"\"\"Compute class probabilities for the input sequence.\n",
    "\n",
    "        Args:\n",
    "            features (torch.Tensor): ids of each token,\n",
    "                size ([bs, seq_length]\n",
    "            attention_mask (torch.Tensor): binary tensor, used to select\n",
    "                tokens which are used to compute attention scores\n",
    "                in the self-attention heads, size [bs, seq_length]\n",
    "            head_mask (torch.Tensor): 1.0 in head_mask indicates that\n",
    "                we keep the head, size: [num_heads]\n",
    "                or [num_hidden_layers x num_heads]\n",
    "        Returns:\n",
    "            PyTorch Tensor with predicted class scores\n",
    "        \"\"\"\n",
    "        assert attention_mask is not None, \"attention mask is none\"\n",
    "\n",
    "        # taking BERTModel output\n",
    "        # see https://huggingface.co/transformers/model_doc/bert.html#transformers.BertModel\n",
    "        distilbert_output = self.model(\n",
    "            input_ids=features, attention_mask=attention_mask, head_mask=head_mask\n",
    "        )\n",
    "        # we only need the hidden state here and don't need\n",
    "        # transformer output, so index 0\n",
    "        # seq_output = bert_output[0]  # (bs, seq_len, dim)\n",
    "        # mean pooling, i.e. getting average representation of all tokens\n",
    "        # pooled_output = seq_output.mean(axis=1)  # (bs, dim)\n",
    "        # pooled_output = self.dropout(pooled_output)  # (bs, dim)\n",
    "        # scores = self.classifier(pooled_output)  # (bs, num_classes)\n",
    "\n",
    "        hidden_state = distilbert_output[0]  # (bs, seq_len, dim)\n",
    "        pooled_output = hidden_state[:, 0]  # (bs, dim)\n",
    "        pooled_output = self.pre_classifier(pooled_output)  # (bs, dim)\n",
    "        pooled_output = nn.ReLU()(pooled_output)  # (bs, dim)\n",
    "        pooled_output = self.dropout(pooled_output)  # (bs, dim)\n",
    "        logits = self.classifier(pooled_output)  # (bs, num_labels)\n",
    "        probs = self.sig(logits)\n",
    "\n",
    "        return probs"
   ]
  },
  {
   "source": [
    "# Train Bert Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst.dl import SupervisedRunner\n",
    "from catalyst.dl.callbacks import (\n",
    "    AccuracyCallback,\n",
    "    CheckpointCallback,\n",
    "    InferCallback,\n",
    "    OptimizerCallback,\n",
    ")\n",
    "from catalyst.utils import prepare_cudnn, set_global_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_loaders, test_loaders = read_data(params, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification(\n",
    "    pretrained_model_name=params[\"model\"][\"model_name\"],\n",
    "    num_classes=params[\"model\"][\"num_classes\"],\n",
    ")\n",
    "\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=float(params[\"training\"][\"learn_rate\"])\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "set_global_seed(SEED)\n",
    "prepare_cudnn(deterministic=True)\n",
    "runner = SupervisedRunner(input_key=(\"features\", \"attention_mask\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst.callbacks.metric import MetricCallback\n",
    "from catalyst.utils.torch import get_activation_fn\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    hamming_loss,\n",
    "    accuracy_score,\n",
    "    multilabel_confusion_matrix,\n",
    "\n",
    ") \n",
    "\n",
    "def preprocess_multi_label_metrics(\n",
    "    outputs,\n",
    "    targets,\n",
    "    weights = None,\n",
    "):\n",
    "\n",
    "    if not torch.is_tensor(outputs):\n",
    "        outputs = torch.from_numpy(outputs)\n",
    "    if not torch.is_tensor(targets):\n",
    "        targets = torch.from_numpy(targets)\n",
    "    if weights is not None:\n",
    "        if not torch.is_tensor(weights):\n",
    "            weights = torch.from_numpy(weights)\n",
    "        weights = weights.squeeze()\n",
    "\n",
    "    if outputs.dim() == 1:\n",
    "        outputs = outputs.view(-1, 1)\n",
    "    else:\n",
    "        assert outputs.dim() == 2, (\n",
    "            \"wrong `outputs` size \"\n",
    "            \"(should be 1D or 2D with one column per class)\"\n",
    "        )\n",
    "\n",
    "    if targets.dim() == 1:\n",
    "        targets = targets.view(-1, 1)\n",
    "    else:\n",
    "        assert targets.dim() == 2, (\n",
    "            \"wrong `targets` size \"\n",
    "            \"(should be 1D or 2D with one column per class)\"\n",
    "        )\n",
    "\n",
    "    if weights is not None:\n",
    "        assert weights.dim() == 1, \"Weights dimension should be 1\"\n",
    "        assert weights.numel() == targets.size(\n",
    "            0\n",
    "        ), \"Weights dimension 1 should be the same as that of target\"\n",
    "        assert torch.min(weights) >= 0, \"Weight should be non-negative only\"\n",
    "\n",
    "    assert torch.equal(\n",
    "        targets ** 2, targets\n",
    "    ), \"targets should be binary (0 or 1)\"\n",
    "\n",
    "    return outputs, targets, weights\n",
    "\n",
    "def multi_label_accuracy(\n",
    "    outputs,\n",
    "    targets,\n",
    "    threshold,\n",
    "    activation = None,\n",
    ") :\n",
    "    outputs, targets, _ = preprocess_multi_label_metrics(\n",
    "        outputs=outputs, targets=targets\n",
    "    )\n",
    "    # print(outputs.size(), targets.size())\n",
    "    # activation_fn = get_activation_fn(activation)\n",
    "    # outputs = activation_fn(outputs)\n",
    "\n",
    "    outputs = (outputs > threshold).long()\n",
    "    # output = (targets.long() == outputs.long()).sum().float() / np.prod(\n",
    "    #     targets.shape\n",
    "    # )\n",
    "    output = accuracy_score(\n",
    "    targets.cpu(),\n",
    "    outputs.cpu(),\n",
    "    )\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "class MultiLabelAccuracyCallback(MetricCallback):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_key: str = \"targets\",\n",
    "        output_key: str = \"logits\",\n",
    "        prefix: str = \"multi_label_accuracy\",\n",
    "        threshold: float = None,\n",
    "        activation: str = \"Sigmoid\",\n",
    "    ):\n",
    "        super().__init__(\n",
    "            prefix=prefix,\n",
    "            metric_fn=multi_label_accuracy,\n",
    "            input_key=input_key,\n",
    "            output_key=output_key,\n",
    "            threshold=threshold,\n",
    "            activation=activation,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "| ID | GPU | MEM |\n------------------\n|  0 |  0% | 25% |\n"
     ]
    }
   ],
   "source": [
    "from GPUtil import showUtilization as gpu_usage\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gpu_usage()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/3 * Epoch (train): 100% 377/377 [00:49<00:00,  7.65it/s, loss=0.071, multi_label_accuracy=0.500]\n",
      "1/3 * Epoch (valid): 100% 47/47 [00:01<00:00, 37.61it/s, loss=0.158, multi_label_accuracy=0.000e+00]\n",
      "[2021-01-13 18:17:00,255] \n",
      "1/3 * Epoch 1 (_base): lr=3.000e-05 | momentum=0.9000\n",
      "1/3 * Epoch 1 (train): loss=0.2475 | multi_label_accuracy=0.0544\n",
      "1/3 * Epoch 1 (valid): loss=0.1180 | multi_label_accuracy=0.3830\n",
      "2/3 * Epoch (train): 100% 377/377 [00:49<00:00,  7.58it/s, loss=0.030, multi_label_accuracy=1.000]\n",
      "2/3 * Epoch (valid): 100% 47/47 [00:01<00:00, 39.66it/s, loss=0.049, multi_label_accuracy=0.500]\n",
      "[2021-01-13 18:18:22,685] \n",
      "2/3 * Epoch 2 (_base): lr=3.000e-05 | momentum=0.9000\n",
      "2/3 * Epoch 2 (train): loss=0.0793 | multi_label_accuracy=0.5584\n",
      "2/3 * Epoch 2 (valid): loss=0.0385 | multi_label_accuracy=0.8511\n",
      "3/3 * Epoch (train): 100% 377/377 [00:49<00:00,  7.56it/s, loss=0.017, multi_label_accuracy=1.000]\n",
      "3/3 * Epoch (valid): 100% 47/47 [00:01<00:00, 39.82it/s, loss=0.023, multi_label_accuracy=1.000]\n",
      "[2021-01-13 18:19:43,995] \n",
      "3/3 * Epoch 3 (_base): lr=3.000e-05 | momentum=0.9000\n",
      "3/3 * Epoch 3 (train): loss=0.0383 | multi_label_accuracy=0.8846\n",
      "3/3 * Epoch 3 (valid): loss=0.0248 | multi_label_accuracy=0.9681\n",
      "Top best models:\n",
      "logdir\\checkpoints/train.3.pth\t0.0248\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loaders=train_val_loaders,\n",
    "    callbacks=[\n",
    "        MultiLabelAccuracyCallback(threshold=params['training']['trashhold']),\n",
    "    ],\n",
    "    logdir=params[\"training\"][\"log_dir\"],\n",
    "    num_epochs=int(params[\"training\"][\"num_epochs\"]),\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=> Loading checkpoint logdir/checkpoints/best.pth\n",
      "loaded state checkpoint logdir/checkpoints/best.pth (global epoch 3, epoch 3, stage train)\n",
      "1/1 * Epoch (test): 100% 48/48 [00:01<00:00, 45.91it/s]\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "with torch.no_grad():\n",
    "    runner.infer(\n",
    "        model=model,\n",
    "        loaders=test_loaders,\n",
    "        callbacks=[\n",
    "            CheckpointCallback(\n",
    "                resume=f\"{params['training']['log_dir']}/checkpoints/best.pth\"\n",
    "            ),\n",
    "            InferCallback(),\n",
    "        ],\n",
    "        verbose=True,\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "| ID | GPU | MEM |\n------------------\n|  0 |  2% | 52% |\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gpu_usage() "
   ]
  },
  {
   "source": [
    "# Run Metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    f1_score, \n",
    "    confusion_matrix, \n",
    "    accuracy_score, \n",
    "    roc_auc_score,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from catalyst.contrib.utils.plotly import plot_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    hamming_loss,\n",
    "    accuracy_score,\n",
    "    multilabel_confusion_matrix,\n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# def f1_sampled(actual, pred, threshold=params['training']['trashhold']):\n",
    "#     #converting the multi-label classification to a binary output\n",
    "#     mlb = MultiLabelBinarizer()\n",
    "#     actual = mlb.fit_transform(actual)\n",
    "\n",
    "#     pred = (torch.sigmoid(torch.tensor(pred, dtype=torch.float32)) > threshold).long()\n",
    "#     print(pred[0])\n",
    "#     pred = mlb.fit_transform(pred)\n",
    "#     #fitting the data for calculating the f1 score \n",
    "#     f1 = f1_score(actual, pred, average = \"samples\")\n",
    "#     return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lastly, saving predicted scores for the test set\n",
    "predicted_scores = runner.callbacks[0].predictions[\"logits\"]\n",
    "np.savetxt(X=predicted_scores,\n",
    "           fname=params[\"data\"][\"path_to_test_pred_scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.0319, 0.0113, 0.9110, 0.0149, 0.0028, 0.0078, 0.0076, 0.0203, 0.0238,\n",
       "        0.0142, 0.0104, 0.0101])"
      ]
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "source": [
    "torch.tensor(predicted_scores[0], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    " import re\n",
    "\n",
    "def features_to_list(features):\n",
    "    res_list = []\n",
    "    for label in features['type'].to_list():\n",
    "        lab_list = re.sub(\"[^0-9]\", \"\", label)\n",
    "        res = [int(n.strip()) for n in lab_list]\n",
    "        res_list.append(res)\n",
    "    return np.array(res_list)\n",
    "\n",
    "def roc_auc(y_true, y_pred, n_classes=params['model']['num_classes']):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    # fpr = dict()\n",
    "    # tpr = dict()\n",
    "    roc_auc = []\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "        roc_auc.append(auc(fpr, tpr))\n",
    "        \n",
    "    # for i in range(n_classes):\n",
    "    #     tense = SENT_TYPES_INVERSE[i]\n",
    "    #     print(f'{tense} => {roc_auc[i]}')\n",
    "    print(f\"Mean roc_auc => {sum(roc_auc) / n_classes}\")\n",
    "# roc_auc(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1 Score => 0.9387558978417704\nAccuracy => 0.9368421052631579\nHumming Loss => 0.009649122807017544\nMean roc_auc => 0.9580836462287338\n"
     ]
    }
   ],
   "source": [
    "def metrics():\n",
    "    f1_y_true = features_to_list(pd.read_csv('mul-test.csv', encoding='utf-8'))\n",
    "    threshold = params['training']['trashhold']\n",
    "    f1_y_pred = (predicted_scores > threshold)\n",
    "\n",
    "    # f1 score\n",
    "    f1_scr = f1_score(\n",
    "        f1_y_true,\n",
    "        f1_y_pred,\n",
    "        average='weighted')\n",
    "    \n",
    "    # accuracy\n",
    "    acc = accuracy_score(f1_y_true, f1_y_pred)\n",
    "    \n",
    "    # humming loss\n",
    "    humming = hamming_loss(f1_y_true, f1_y_pred)\n",
    "    print(f'F1 Score => {f1_scr}\\nAccuracy => {acc}\\nHumming Loss => {humming}')\n",
    "    roc_auc(f1_y_true, f1_y_pred)\n",
    "metrics()"
   ]
  },
  {
   "source": [
    "## f1 score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9387558978417704"
      ]
     },
     "metadata": {},
     "execution_count": 164
    }
   ],
   "source": [
    "f1_y_true = features_to_list(pd.read_csv('mul-test.csv', encoding='utf-8'))\n",
    "threshold = params['training']['trashhold']\n",
    "# f1_y_pred = (torch.tensor(predicted_scores, dtype=torch.float32) > threshold).long()\n",
    "f1_y_pred = (predicted_scores > threshold)\n",
    "f1_score(\n",
    "    f1_y_true,\n",
    "    f1_y_pred,\n",
    "    average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "55 -43"
   ]
  },
  {
   "source": [
    "## Accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9368421052631579"
      ]
     },
     "metadata": {},
     "execution_count": 161
    }
   ],
   "source": [
    "accuracy_score(f1_y_true, f1_y_pred, normalize=True, sample_weight=None)"
   ]
  },
  {
   "source": [
    "## Humming Loss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.009649122807017544"
      ]
     },
     "metadata": {},
     "execution_count": 158
    }
   ],
   "source": [
    "hamming_loss(f1_y_true, f1_y_pred)"
   ]
  },
  {
   "source": [
    "## ROC AUC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    from sklearn import datasets\n",
    "    from sklearn.multiclass import OneVsRestClassifier\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    #from sklearn.cross_validation import train_test_split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib\n",
    "\n",
    "    iris = datasets.load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "\n",
    "    y = label_binarize(y, classes=[0,1,2])\n",
    "    n_classes = 3\n",
    "\n",
    "    # shuffle and split training and test sets\n",
    "    X_train, X_test, y_train, y_test =\\\n",
    "        train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "    # classifier\n",
    "    clf = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "    y_score = clf.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # # Plot of a ROC curve for a specific class\n",
    "    # for i in range(n_classes):\n",
    "    #     plt.figure()\n",
    "    #     plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "    #     plt.plot([0, 1], [0, 1], 'k--')\n",
    "    #     plt.xlim([0.0, 1.0])\n",
    "    #     plt.ylim([0.0, 1.05])\n",
    "    #     plt.xlabel('False Positive Rate')\n",
    "    #     plt.ylabel('True Positive Rate')\n",
    "    #     plt.title('Receiver operating characteristic example')\n",
    "    #     plt.legend(loc=\"lower right\")\n",
    "    #     plt.show()\n",
    "    print(roc_auc)\n",
    "# test()"
   ]
  },
  {
   "source": [
    "# Visual checking"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst import utils\n",
    "SENT_TYPES_INVERSE = {i:item for i, item in enumerate(SENT_TYPES)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: 'present_continuous',\n",
       " 1: 'to_be_future',\n",
       " 2: 'past_continuous',\n",
       " 3: 'past_simple',\n",
       " 4: 'can',\n",
       " 5: 'future_simple',\n",
       " 6: 'to_be_present',\n",
       " 7: 'used_to',\n",
       " 8: 'to_be_past',\n",
       " 9: 'present_simple',\n",
       " 10: 'present_perfect',\n",
       " 11: 'could'}"
      ]
     },
     "metadata": {},
     "execution_count": 148
    }
   ],
   "source": [
    "SENT_TYPES_INVERSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sent_type(sent, threshold= params['training']['trashhold']):\n",
    "    with torch.no_grad():\n",
    "        x = sent\n",
    "        tokenizer = AutoTokenizer.from_pretrained(params['model']['model_name'])\n",
    "        output_dict = tokenizer.encode_plus(\n",
    "                x,\n",
    "                add_special_tokens=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=params['model']['max_seq_length'],\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "            )\n",
    "        bert_model = BertForSequenceClassification(\n",
    "            pretrained_model_name=params[\"model\"][\"model_name\"],\n",
    "            num_classes=params[\"model\"][\"num_classes\"],\n",
    "        )\n",
    "        bert_model.cuda()\n",
    "        bert_model.eval()\n",
    "\n",
    "        checkpoint = utils.checkpoint.load_checkpoint(filepath=\"./logdir/checkpoints/best.pth\")\n",
    "        utils.checkpoint.unpack_checkpoint(\n",
    "            checkpoint=checkpoint,\n",
    "            model=bert_model,\n",
    "            # optimizer=optimizer,\n",
    "            # criterion=criterion\n",
    "            )\n",
    "        output_preds = bert_model(output_dict['input_ids'].cuda(), output_dict['attention_mask'].cuda())\n",
    "        # output = int(torch.argmax(output).item())\n",
    "        # probs = torch.sigmoid(torch.tensor(output_preds, dtype=torch.float32))\n",
    "        output = (output_preds > threshold).long()[0]\n",
    "        with np.printoptions(precision=3, suppress=True):\n",
    "            print(output_preds.detach().cpu().numpy()[0])\n",
    "        # print(output)\n",
    "        pred_tenses = [SENT_TYPES_INVERSE[i] for i, num in enumerate(list(output)) if int(num) == 1]\n",
    "        if len(pred_tenses) == 0:\n",
    "            # print(torch.argmax(output_preds).item())\n",
    "            pred_tenses = SENT_TYPES_INVERSE[int(torch.argmax(output_preds).item())]\n",
    "        result = f'{sent} - {pred_tenses}'\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.003 0.002 0.002 0.001 0.002 0.002 0.092 0.002 0.002 0.907 0.007 0.001]\nI'm Tomas and I live in Vienna with my parents and my sisters - ['present_simple']\n"
     ]
    }
   ],
   "source": [
    "present_simple = [\n",
    "    # 'Do you play the piano?',\n",
    "    # 'Do Rita and Angela live in Manchester?',\n",
    "    # 'What does Angela do?',\n",
    "    # 'Who plays football at the weekend?',\n",
    "    # \"I don't play the piano but I play the guitar.\",\n",
    "    # \"I don't live in London now.\",\n",
    "    # \"John doesn't live in Manchester.\",\n",
    "    # \"Light travels at almost 300,000 kilometres per second.\",\n",
    "    # \"The school term starts next week.\",\n",
    "    # \"I am good at math, I also like history and geography\",\n",
    "    \"I'm Tomas and I live in Vienna with my parents and my sisters\"\n",
    "]\n",
    "for sent in present_simple:\n",
    "    print(predict_sent_type(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.924 0.034 0.049 0.012 0.029 0.015 0.198 0.013 0.006 0.013 0.004 0.013\n",
      " 0.008]\n",
      "I'm just leaving work. - ['present_continuous']\n",
      "[0.912 0.026 0.053 0.01  0.02  0.009 0.225 0.011 0.005 0.01  0.003 0.014\n",
      " 0.007]\n",
      "The children are sleeping. - ['present_continuous']\n",
      "[0.927 0.026 0.064 0.012 0.018 0.01  0.094 0.012 0.005 0.013 0.003 0.014\n",
      " 0.008]\n",
      "Mary is going to a new school next term. - ['present_continuous']\n",
      "[0.921 0.022 0.056 0.011 0.019 0.01  0.167 0.013 0.006 0.012 0.003 0.014\n",
      " 0.007]\n",
      "What are you doing next week? - ['present_continuous']\n",
      "[0.922 0.022 0.068 0.01  0.018 0.009 0.186 0.013 0.006 0.011 0.003 0.016\n",
      " 0.007]\n",
      "Are you listening? - ['present_continuous']\n",
      "[0.908 0.023 0.064 0.008 0.015 0.008 0.128 0.011 0.005 0.011 0.002 0.011\n",
      " 0.006]\n",
      "When is she going home? - ['present_continuous']\n",
      "[0.919 0.025 0.054 0.01  0.019 0.009 0.136 0.01  0.005 0.009 0.003 0.019\n",
      " 0.007]\n",
      "Are they coming to your party? - ['present_continuous']\n",
      "[0.879 0.022 0.036 0.006 0.018 0.007 0.224 0.008 0.004 0.007 0.002 0.023\n",
      " 0.005]\n",
      "hey aren't coming to the party. - ['present_continuous']\n",
      "[0.814 0.017 0.022 0.008 0.02  0.008 0.486 0.01  0.004 0.009 0.002 0.014\n",
      " 0.004]\n",
      "These days most people are using email instead of writing letters. - ['present_continuous']\n",
      "[0.911 0.036 0.037 0.012 0.028 0.016 0.19  0.012 0.005 0.011 0.004 0.016\n",
      " 0.007]\n",
      "I'm working in London for the next two weeks. - ['present_continuous']\n",
      "[0.93  0.029 0.066 0.011 0.022 0.012 0.122 0.012 0.006 0.012 0.003 0.014\n",
      " 0.008]\n",
      "He's studying history. - ['present_continuous']\n",
      "[0.9   0.024 0.039 0.012 0.021 0.009 0.283 0.011 0.005 0.011 0.003 0.017\n",
      " 0.006]\n",
      "The children are growing up quickly. - ['present_continuous']\n"
     ]
    }
   ],
   "source": [
    "present_continuous = [\n",
    "    \"I'm just leaving work.\",\n",
    "    \"The children are sleeping.\",\n",
    "    \"Mary is going to a new school next term.\",\n",
    "    \"What are you doing next week?\",\n",
    "    \"Are you listening?\",\n",
    "    \"When is she going home?\",\n",
    "    \"Are they coming to your party?\",\n",
    "    \"hey aren't coming to the party.\",\n",
    "    \"These days most people are using email instead of writing letters.\",\n",
    "    \"I'm working in London for the next two weeks.\",\n",
    "    \"He's studying history.\",\n",
    "    \"The children are growing up quickly.\",\n",
    "]\n",
    "for sent in present_continuous:\n",
    "    print(predict_sent_type(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.002 0.003 0.001 0.003 0.002 0.002 0.024 0.001 0.001 0.977 0.    0.007\n",
      " 0.001]\n",
      "\n",
      "My working day starts very early. - ['present_simple']\n",
      "[0.002 0.003 0.001 0.002 0.002 0.002 0.027 0.001 0.001 0.971 0.    0.008\n",
      " 0.001]\n",
      "From Monday to Friday I get up at half past three - ['present_simple']\n",
      "[0.002 0.003 0.001 0.002 0.002 0.002 0.033 0.001 0.001 0.975 0.    0.009\n",
      " 0.001]\n",
      "and I have a shower and a cup of coffee. - ['present_simple']\n",
      "[0.002 0.004 0.001 0.003 0.002 0.003 0.012 0.001 0.001 0.983 0.    0.007\n",
      " 0.001]\n",
      "I usually leave the house at ten past four because the car always arrives a few minutes early. - ['present_simple']\n",
      "[0.002 0.003 0.002 0.003 0.003 0.003 0.015 0.001 0.001 0.983 0.    0.006\n",
      " 0.001]\n",
      "I get to the studio at about five o'clock and start work. - ['present_simple']\n",
      "[0.002 0.003 0.001 0.002 0.002 0.002 0.023 0.001 0.001 0.976 0.    0.007\n",
      " 0.001]\n",
      "My programme Good Morning Britain starts at seven o'clock and finishes at nine o'clock. - ['present_simple']\n",
      "[0.002 0.003 0.001 0.003 0.002 0.003 0.014 0.001 0.001 0.982 0.    0.006\n",
      " 0.001]\n",
      "Then I leave the studio at a quarter past ten. - ['present_simple']\n",
      "[0.002 0.003 0.001 0.003 0.002 0.003 0.014 0.001 0.001 0.984 0.    0.005\n",
      " 0.001]\n",
      "After that, I go shopping and visit some friends. - ['present_simple']\n",
      "[0.002 0.004 0.001 0.003 0.002 0.003 0.026 0.001 0.001 0.976 0.    0.007\n",
      " 0.001]\n",
      "I get home at three o'clock. - ['present_simple']\n",
      "[0.002 0.003 0.002 0.004 0.003 0.003 0.01  0.002 0.002 0.986 0.    0.006\n",
      " 0.002]\n",
      "A woman helps me with the housework and the ironing. - ['present_simple']\n",
      "[0.002 0.003 0.002 0.003 0.002 0.003 0.015 0.002 0.002 0.985 0.    0.006\n",
      " 0.002]\n",
      "I read a newspaper and do some work.\n",
      " - ['present_simple']\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "some_text = \"\"\"\n",
    "My working day starts very early. From Monday to Friday I get up at half past three and I have a shower and a cup of coffee. I usually leave the house at ten past four because the car always arrives a few minutes early. I get to the studio at about five o'clock and start work. My programme Good Morning Britain starts at seven o'clock and finishes at nine o'clock. Then I leave the studio at a quarter past ten. After that, I go shopping and visit some friends. I get home at three o'clock. A woman helps me with the housework and the ironing. I read a newspaper and do some work.\n",
    "\"\"\"\n",
    "\n",
    "for sent in nlp(some_text).sents:\n",
    "    sent = str(sent)\n",
    "    print(predict_sent_type(sent))"
   ]
  }
 ]
}