{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nerda_copy_library",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrA8LQwh1pMY",
        "outputId": "ae4eb8a9-a2a7-4a05-c98b-408ab647eaa8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#!ls \"/content/drive/My Drive/collab_sandbox\"\n",
        "%cd drive/MyDrive/collab_sandbox/NER/ner_tenses_recognition/\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/collab_sandbox/NER/ner_tenses_recognition\n",
            "advanced_tutorial_crf_lstm.ipynb  NERDA_models\n",
            "best-val-model-86.pt\t\t  NER_SANDBOX.ipynb\n",
            "catalyst_ner\t\t\t  NER_tenses_pytorch_lighting_catalyst\n",
            "datasets\t\t\t  ner_tenses_recognition_conll_type.ipynb\n",
            "index.html\t\t\t  ner-test.csv\n",
            "logs\t\t\t\t  results\n",
            "my_nerda\t\t\t  spacy_ner\n",
            "my_pure_pytorch\t\t\t  spacy_recognition\n",
            "nerda_copy_library\t\t  Token_classification.ipynb\n",
            "NERDA.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZOoh43Yg6nS"
      },
      "source": [
        "!pip install 'transformers<=3.5.1' 'torch<=1.7.1' pytorch-crf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RFQYWAWsjFt",
        "outputId": "5c782bd4-7bfb-4a18-dc86-3d82927acc5b"
      },
      "source": [
        "a = torch.randn(4, 128, 768) \n",
        "b = torch.randn(4, 768).repeat(128, 1, 1).permute(1, 0, 2)\n",
        "torch.cat([a, b], dim=2).shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 128, 1536])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37C8tv0wiv-4"
      },
      "source": [
        "import torch\n",
        "import sklearn\n",
        "import warnings\n",
        "import transformers\n",
        "# import sklearn.preprocessing\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.nn as nn\n",
        "from transformers import AutoConfig\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "# import sklearn.preprocessing\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
        "from typing import List\n",
        "from typing import List\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import warnings\n",
        "from tqdm import tqdm_notebook\n",
        "# from catalyst.contrib.nn.optimizers import RAdam, Lookahead, QHAdamW, AdamP\n",
        "from torchcrf import CRF\n",
        "\n",
        "class NERDADataSetReader():\n",
        "    def __init__(self, \n",
        "                sentences, \n",
        "                tags, \n",
        "                transformer_tokenizer, \n",
        "                transformer_config, \n",
        "                tag_encoder, \n",
        "                tag_outside\n",
        "            ):\n",
        "        self.sentences = sentences\n",
        "        self.tags = tags\n",
        "        self.transformer_tokenizer = transformer_tokenizer\n",
        "        self.max_len = 128\n",
        "        self.tag_encoder = tag_encoder\n",
        "        self.pad_token_id = transformer_config.pad_token_id\n",
        "        self.tag_outside_transformed = tag_encoder.transform([tag_outside])[0]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        sentence = self.sentences[item]\n",
        "        tags = self.tags[item]\n",
        "        # encode tags\n",
        "        tags = self.tag_encoder.transform(tags)\n",
        "        \n",
        "        # check inputs for consistancy\n",
        "        assert len(sentence) == len(tags)\n",
        "\n",
        "        input_ids = []\n",
        "        target_tags = []\n",
        "        tokens = []\n",
        "        offsets = []\n",
        "        \n",
        "        # for debugging purposes\n",
        "        # print(item)\n",
        "        for i, word in enumerate(sentence):\n",
        "            # bert tokenization\n",
        "            wordpieces = self.transformer_tokenizer.tokenize(word)\n",
        "            tokens.extend(wordpieces)\n",
        "            # make room for CLS\n",
        "            offsets.extend([1]+[0]*(len(wordpieces)-1))\n",
        "            # Extends the ner_tag if the word has been split by the wordpiece tokenizer\n",
        "            target_tags.extend([tags[i]] * len(wordpieces)) \n",
        "        \n",
        "        # Make room for adding special tokens (one for both 'CLS' and 'SEP' special tokens)\n",
        "        # max_len includes _all_ tokens.\n",
        "        if len(tokens) > self.max_len - 2:\n",
        "            msg = f'Sentence #{item} length {len(tokens)} exceeds max_len {self.max_len} and has been truncated'\n",
        "            warnings.warn(msg)\n",
        "        tokens = tokens[:self.max_len - 2] \n",
        "        target_tags = target_tags[:self.max_len - 2]\n",
        "        offsets = offsets[:self.max_len - 2]\n",
        "\n",
        "        # encode tokens for BERT\n",
        "        input_ids = self.transformer_tokenizer.encode(tokens)\n",
        "        \n",
        "        # fill out other inputs for model.    \n",
        "        target_tags = [self.tag_outside_transformed] + target_tags + [self.tag_outside_transformed] \n",
        "        masks = [1] * len(input_ids)\n",
        "        # set to 0, because we are not doing NSP or QA type task (across multiple sentences)\n",
        "        # token_type_ids distinguishes sentences.\n",
        "        token_type_ids = [0] * len(input_ids) \n",
        "        offsets = [1] + offsets + [1]\n",
        "\n",
        "        # Padding to max length \n",
        "        # compute padding length\n",
        "        padding_len = self.max_len - len(input_ids)\n",
        "        input_ids = input_ids + ([self.pad_token_id] * padding_len)\n",
        "        masks = masks + ([0] * padding_len)  \n",
        "        offsets = offsets + ([0] * padding_len)\n",
        "        token_type_ids = token_type_ids + ([0] * padding_len)\n",
        "        target_tags = target_tags + ([self.tag_outside_transformed] * padding_len)  \n",
        "\n",
        "        return {'input_ids' : torch.tensor(input_ids, dtype = torch.long),\n",
        "                'masks' : torch.tensor(masks, dtype = torch.long),\n",
        "                'token_type_ids' : torch.tensor(token_type_ids, dtype = torch.long),\n",
        "                'target_tags' : torch.tensor(target_tags, dtype = torch.long),\n",
        "                'offsets': torch.tensor(offsets, dtype = torch.long)} \n",
        "      \n",
        "\n",
        "def flatten(l):\n",
        "    return [item for sublist in l for item in sublist]\n",
        "\n",
        "def compute_f1_scores(y_pred, y_true, labels, average=None): \n",
        "    # check inputs.\n",
        "    assert sum([len(t) < len(p) for t, p in zip(y_true, y_pred)]) == 0, \"Length of predictions must not exceed length of observed values\"\n",
        "\n",
        "    # check, if some lengths of observed values exceed predicted values.\n",
        "    n_exceeds = sum([len(t) > len(p) for t, p in zip(y_true, y_pred)])\n",
        "\n",
        "    # truncate observed values dimensions to match predicted values,\n",
        "    # this is needed if predictions have been truncated earlier in \n",
        "    # the flow.\n",
        "    y_true = [t[:len(p)] for t, p in zip(y_true, y_pred)]\n",
        "    \n",
        "    y_pred = flatten(y_pred)\n",
        "    y_true = flatten(y_true) \n",
        "\n",
        "    f1_scores = precision_recall_fscore_support(y_true = y_true,\n",
        "                                                y_pred = y_pred,\n",
        "                                                labels = labels,\n",
        "                                                average=average) \n",
        "\n",
        "    return f1_scores\n",
        "\n",
        "\n",
        "\n",
        "class NERDANetwork(nn.Module):\n",
        "    def __init__(self, transformer, device, n_tags, dropout = 0.1):\n",
        "        super(NERDANetwork, self).__init__()\n",
        "        transformer_name = transformer.name_or_path\n",
        "        transformer_config = AutoConfig.from_pretrained(transformer_name)\n",
        "        self.transformer = transformer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.tags = nn.Linear(transformer_config.hidden_size, n_tags)\n",
        "        self.device = device\n",
        "        # self.norm_1 = nn.BatchNorm1d(128)\n",
        "        # self.norm_2 = nn.BatchNorm1d(128)\n",
        "\n",
        "    def forward(self, \n",
        "                input_ids: torch.Tensor, \n",
        "                masks: torch.Tensor, \n",
        "                token_type_ids: torch.Tensor, \n",
        "                target_tags: torch.Tensor, \n",
        "                offsets: torch.Tensor \n",
        "                ):\n",
        "        transformer_inputs = {\n",
        "            'input_ids': input_ids.to(self.device),\n",
        "            'attention_mask': masks.to(self.device),\n",
        "            }\n",
        "        outputs = self.transformer(**transformer_inputs)[0]\n",
        "        # print(outputs.shape, outputs[:, 0].shape)\n",
        "        \n",
        "        # assert False\n",
        "\n",
        "        # sent = outputs[:, 0].repeat(128, 1, 1).permute(1, 0, 2)\n",
        "        # outputs = self.norm_1(outputs)\n",
        "        outputs = self.dropout(outputs)\n",
        "        # outputs = torch.tanh(outputs + sent)\n",
        "        # outputs = torch.tanh(torch.cat([outputs, sent], dim=2))\n",
        "        # outputs = self.dropout(outputs)\n",
        "        # outputs = self.norm_2(outputs)\n",
        "        outputs = self.tags(outputs)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class NERDA:\n",
        "    def __init__(self, \n",
        "                 model_name = 'roberta-base',\n",
        "                 tag_scheme = None,\n",
        "                 tag_outside = 'O',\n",
        "                 dataset_training = None,\n",
        "                 dataset_validation = None,\n",
        "                 max_len = 128,\n",
        "                 network = NERDANetwork,\n",
        "                 train_batch_size = 4,\n",
        "                 dropout = 0.1,\n",
        "                 grad_clip = 1,\n",
        "                 optimizer_class = AdamW,\n",
        "                 ):\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.tag_scheme = tag_scheme\n",
        "        self.tag_outside = tag_outside\n",
        "        self.model_name = model_name  \n",
        "        self.dataset_training = dataset_training\n",
        "        self.dataset_validation = dataset_validation\n",
        "        # self.hyperparameters = hyperparameters\n",
        "        self.tag_outside = tag_outside\n",
        "        self.tag_scheme = tag_scheme\n",
        "        tag_complete = [tag_outside] + tag_scheme\n",
        "        # fit encoder to _all_ possible tags.\n",
        "        self.max_len = max_len\n",
        "        self.tag_encoder = sklearn.preprocessing.LabelEncoder()\n",
        "        self.tag_encoder.fit(tag_complete)\n",
        "        self.transformer_model = AutoModel.from_pretrained(model_name)\n",
        "        self.transformer_tokenizer = AutoTokenizer.from_pretrained(model_name, \n",
        "                                                                  #  **tokenizer_parameters\n",
        "                                                                   do_lower_case=True\n",
        "                                                                   )\n",
        "        self.transformer_config = AutoConfig.from_pretrained(model_name)  \n",
        "        self.network = NERDANetwork(self.transformer_model, self.device, len(tag_complete), dropout = dropout)\n",
        "        self.network.to(self.device)\n",
        "        # self.validation_batch_size = validation_batch_size\n",
        "        self.train_losses = []\n",
        "        self.valid_loss = np.nan\n",
        "        self.train_batch_size = train_batch_size\n",
        "        self.dl_train = None\n",
        "        self.dl_validate = None\n",
        "        self.scheduler = None\n",
        "        self.n_tags = self.tag_encoder.classes_.shape[0]\n",
        "        self.optimizer = None\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "        self.clip = grad_clip\n",
        "        self.optimizer_class = optimizer_class\n",
        "        self.model_crf = CRF(51)\n",
        "        self.model_crf.to(self.device)\n",
        "        \n",
        "\n",
        "    def experiment(self, \n",
        "                    epochs = 10,\n",
        "                    warmup_steps = 300,\n",
        "                    learning_rate = 5e-5,\n",
        "                   ):\n",
        "        self.setup()\n",
        "        self.n_tags = self.tag_encoder.classes_.shape[0]\n",
        "\n",
        "        optimizer_parameters = self.network.parameters()\n",
        "\n",
        "        num_train_steps = int(len(self.dataset_training.get('sentences')) / self.train_batch_size * epochs)\n",
        "        \n",
        "        self.optimizer = self.optimizer_class(optimizer_parameters, lr = learning_rate)\n",
        "        self.scheduler = get_linear_schedule_with_warmup(\n",
        "            self.optimizer, num_warmup_steps = warmup_steps, num_training_steps = num_train_steps\n",
        "        )\n",
        "\n",
        "        train_losses = []\n",
        "        best_valid_loss = 10\n",
        "        best_parameters = None\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            \n",
        "            print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "\n",
        "            train_loss = self.train()\n",
        "            train_losses.append(train_loss)\n",
        "            valid_loss = self.validate()\n",
        "\n",
        "            print(f\"Train Loss = {train_loss} Valid Loss = {valid_loss}\")\n",
        "\n",
        "            if valid_loss < best_valid_loss:\n",
        "                best_parameters = self.network.state_dict()            \n",
        "                best_valid_loss = valid_loss\n",
        "        print(f\"Best val => {best_valid_loss}\")\n",
        "        # self.network.load_state_dict(best_parameters)\n",
        "        \n",
        "\n",
        "        return \"Model trained successfully\"\n",
        "    def setup(self):\n",
        "      # prepare datasets for modelling by creating data readers and loaders\n",
        "      self.dl_train = self.create_dataloader(sentences = self.dataset_training.get('sentences'),\n",
        "                                  tags = self.dataset_training.get('tags'), \n",
        "                                )\n",
        "      self.dl_validate = self.create_dataloader(sentences = self.dataset_validation.get('sentences'), \n",
        "                                      tags = self.dataset_validation.get('tags'),\n",
        "                                    )\n",
        "\n",
        "    def create_dataloader(self, sentences, tags):\n",
        "      \n",
        "      data_reader = NERDADataSetReader(\n",
        "          sentences = sentences, \n",
        "          tags = tags,\n",
        "          transformer_tokenizer = self.transformer_tokenizer, \n",
        "          transformer_config = self.transformer_config,\n",
        "          tag_encoder = self.tag_encoder,\n",
        "          tag_outside = self.tag_outside)\n",
        "\n",
        "      data_loader = torch.utils.data.DataLoader(\n",
        "          data_reader, batch_size = self.train_batch_size, num_workers = 2\n",
        "      )\n",
        "\n",
        "      return data_loader\n",
        "    def train(self,):\n",
        "      self.network.train()    \n",
        "      final_loss = 0.0\n",
        "      \n",
        "      for dl in tqdm(self.dl_train, total=len(self.dl_train)):\n",
        "\n",
        "          self.optimizer.zero_grad()\n",
        "          outputs = self.network(**dl)\n",
        "          loss = self.compute_loss(outputs, \n",
        "                              dl.get('target_tags'),\n",
        "                              dl.get('masks'), \n",
        "                              )\n",
        "          # loss = self.network(**dl)\n",
        "          loss.backward()\n",
        "          # torch.nn.utils.clip_grad_norm_(self.network.parameters(), self.clip)\n",
        "          self.optimizer.step()\n",
        "          self.scheduler.step()\n",
        "          final_loss += loss.item()\n",
        "\n",
        "      return final_loss / len(self.dl_train)\n",
        "    def validate(self):\n",
        "        self.network.eval()\n",
        "        final_loss = 0.0\n",
        "\n",
        "        for dl in tqdm(self.dl_validate, total=len(self.dl_validate)):\n",
        "            \n",
        "            outputs = self.network(**dl)\n",
        "            loss = self.compute_loss(outputs, \n",
        "                                dl.get('target_tags'),\n",
        "                                dl.get('masks'), \n",
        "                                )\n",
        "            # loss = self.network(**dl)\n",
        "            final_loss += loss.item()\n",
        "        \n",
        "        return final_loss / len(self.dl_validate)   \n",
        "    def compute_loss(self, preds, target_tags, masks,):\n",
        "        # ----------- CRF -----------------\n",
        "        # preds = preds.permute(1, 0, 2).to(self.device)\n",
        "        # target_tags = target_tags.permute(1, 0).type(torch.long).to(self.device)\n",
        "        # target_tags = target_tags.type(torch.uint8)\n",
        "        # masks = masks.permute(1, 0).type(torch.uint8).to(self.device)\n",
        "        # print(target_tags, masks)\n",
        "        # masks = masks.type(torch.uint8)\n",
        "        # print(preds.shape, target_tags.shape, masks.shape)\n",
        "        # loss = self.model_crf(preds, target_tags, mask=masks)\n",
        "        # ----------- CRF -----------------\n",
        "        active_loss = masks.view(-1) == 1\n",
        "\n",
        "        active_logits = preds.view(-1, self.n_tags)\n",
        "        active_labels = torch.where(\n",
        "            active_loss,\n",
        "            target_tags.view(-1),\n",
        "            torch.tensor(self.criterion.ignore_index).type_as(target_tags)\n",
        "        )\n",
        "        active_labels = torch.as_tensor(active_labels, device = self.device, dtype = torch.long)\n",
        "        loss = self.criterion(active_logits, active_labels)\n",
        "        return loss\n",
        "    def evaluate_performance(self, dataset):\n",
        "        \n",
        "        tags_predicted = self.predict(dataset.get('sentences'))\n",
        "        \n",
        "        f1 = compute_f1_scores(y_pred = tags_predicted, \n",
        "                               y_true = dataset.get('tags'),\n",
        "                               labels = self.tag_scheme,\n",
        "                               average = None\n",
        "                               )\n",
        "        \n",
        "        # create DataFrame with performance scores (=F1)\n",
        "        df = list(zip(self.tag_scheme, f1[2]))\n",
        "        df = pd.DataFrame(df, columns = ['Level', 'F1-Score'])    \n",
        "        \n",
        "        # compute MICRO-averaged F1-scores and add to table.\n",
        "        f1_micro = compute_f1_scores(y_pred = tags_predicted, \n",
        "                                     y_true = dataset.get('tags'),\n",
        "                                     labels = self.tag_scheme,\n",
        "                                     average = 'micro')\n",
        "        f1_micro = pd.DataFrame({'Level' : ['AVG_MICRO'], 'F1-Score': [f1_micro[2]]})\n",
        "        df = df.append(f1_micro)\n",
        "\n",
        "        # compute MACRO-averaged F1-scores and add to table.\n",
        "        f1_macro = compute_f1_scores(y_pred = tags_predicted, \n",
        "                                     y_true = dataset.get('tags'),\n",
        "                                     labels = self.tag_scheme,\n",
        "                                     average = 'macro')\n",
        "        f1_macro = pd.DataFrame({'Level' : ['AVG_MACRO'], 'F1-Score': [f1_macro[2]]})\n",
        "        df = df.append(f1_macro)\n",
        "      \n",
        "        return df \n",
        "    def predict(self, sentences):\n",
        "      self.network.eval()\n",
        "\n",
        "      tag_fill = [self.tag_encoder.classes_[0]]\n",
        "      tags_dummy = [tag_fill * len(sent) for sent in sentences]\n",
        "      \n",
        "      dl_test = self.create_dataloader(sentences=sentences, tags = tags_dummy)\n",
        "\n",
        "      predictions = []\n",
        "      with torch.no_grad():\n",
        "        for i, dl in enumerate(dl_test): \n",
        "          outputs = self.network(**dl)   \n",
        "          # outputs = self.network.predict(**dl)   \n",
        "          # print(outputs)\n",
        "          for i in range(len(outputs)):\n",
        "              preds = self.tag_encoder.inverse_transform(\n",
        "                  outputs[i].argmax(-1).cpu().numpy()\n",
        "              )\n",
        "              # preds = self.tag_encoder.inverse_transform(\n",
        "              #     outputs[i]\n",
        "              # )\n",
        "              # preds = outputs[i]\n",
        "              preds = [prediction for prediction, offset in zip(preds.tolist(), dl.get('offsets')[i]) if offset]\n",
        "              preds = preds[1:-1]\n",
        "              predictions.append(preds)\n",
        "\n",
        "      return predictions"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcwhGVQIoeXF"
      },
      "source": [
        "# model.evaluate_performance(get_conll_data('test'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUG1facm0k9H"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "import numpy as np\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "SEED = 1234\n",
        " \n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "full_dataset = pd.read_csv('./datasets/combined_24_02_2021_conll2003.csv', encoding='utf-8') \n",
        "train, valid, test = np.split(full_dataset.sample(frac=1, random_state=42), \n",
        "                       [int(.7*len(full_dataset)), int(.85*len(full_dataset))])\n",
        "\n",
        "get_sent_data = lambda df, field: [str(item).split() for item in df[field]]\n",
        "get_label_data = lambda df, field: [str(item).split() for item in df[field]]\n",
        "train_data = {\n",
        "    'sentences': get_sent_data(train, 'sent'), \n",
        "    'tags': get_label_data(train, 'named_entity')\n",
        "}\n",
        "valid_data = {\n",
        "    'sentences': get_sent_data(valid, 'sent'), \n",
        "    'tags': get_label_data(valid, 'named_entity')\n",
        "}\n",
        "test_data = {\n",
        "    'sentences': get_sent_data(test, 'sent'), \n",
        "    'tags': get_label_data(test, 'named_entity')\n",
        "}\n",
        "\n",
        "tag_scheme = {\n",
        "  # \"O\": 0,\n",
        "  'B-a1_be_have_do_in_the_past':1,\n",
        "  'B-a1_can':2,\n",
        "  'B-a1_comparative_exept':3,\n",
        "  'B-a1_comparative_long':4,\n",
        "  'B-a1_comparative_short':5,\n",
        "  'B-a1_future_simple':6,\n",
        "  'B-a1_have_has_got':7,\n",
        "  'B-a1_past_simple_irreg':8,\n",
        "  'B-a1_past_simple_reg':9,\n",
        "  'B-a1_possesive_s_sing':10,\n",
        "  'B-a1_possessive_s_plurar':11,\n",
        "  'B-a1_present_continuous_act_rn':12,\n",
        "  'B-a1_present_simple_3d_pers':13,\n",
        "  'B-a1_present_simple_reg_act':14,\n",
        "  'B-a1_special_questions':15,\n",
        "  'B-a1_superlative_exept':16,\n",
        "  'B-a1_superlative_long':17,\n",
        "  'B-a1_superlative_short':18,\n",
        "  'B-a1_there_is_am_are':19,\n",
        "  'B-a1_there_was_were':20,\n",
        "  'B-a1_there_will_be':21,\n",
        "  'B-a1_to_be_future_will_be':22,\n",
        "  'B-a1_to_be_past_was_were':23,\n",
        "  'B-a1_to_be_present_is_am_are':24,\n",
        "  'B-a1_want_would_like_to':25,\n",
        "  # inside\n",
        "  'I-a1_can':26,\n",
        "  'I-a1_comparative_exept':27,\n",
        "  'I-a1_comparative_long':28,\n",
        "  'I-a1_comparative_short':29,\n",
        "  'I-a1_future_simple':30,\n",
        "  'I-a1_have_has_got':31,\n",
        "  'I-a1_past_simple_irreg':32,\n",
        "  'I-a1_past_simple_reg':33,\n",
        "  'I-a1_possesive_s_sing':34,\n",
        "  'I-a1_possessive_s_plurar':35,\n",
        "  'I-a1_present_continuous_act_rn':36,\n",
        "  'I-a1_present_simple_3d_pers':37,\n",
        "  'I-a1_present_simple_reg_act':38,\n",
        "  'I-a1_special_questions':39,\n",
        "  'I-a1_superlative_exept':40,\n",
        "  'I-a1_superlative_long':41,\n",
        "  'I-a1_superlative_short':42,\n",
        "  'I-a1_there_is_am_are':43,\n",
        "  'I-a1_there_was_were':44,\n",
        "  'I-a1_there_will_be':45,\n",
        "  'I-a1_to_be_future_will_be':46,\n",
        "  'I-a1_to_be_past_was_were':47,\n",
        "  'I-a1_to_be_present_is_am_are':48,\n",
        "  'I-a1_want_would_like_to':49,\n",
        "  'I-a1_be_have_do_in_the_past':50,\n",
        "}\n",
        "\n",
        "tag_scheme = list(tag_scheme.keys())\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XEvzPFETVgE",
        "outputId": "48ea7d3e-abb0-4701-8cbe-1fe9c7e0f2e1"
      },
      "source": [
        "len(train_data['sentences']), len(valid_data['sentences'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(490, 105)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3flFrTO13ge"
      },
      "source": [
        "model = NERDA(\n",
        "  dataset_training = train_data,\n",
        "  dataset_validation = valid_data,\n",
        "  tag_scheme = tag_scheme, \n",
        "  model_name = 'roberta-base',\n",
        "  dropout=0.2,\n",
        "  train_batch_size=4,\n",
        "  # grad_clip=100,\n",
        "  optimizer_class=AdamW\n",
        ")\n",
        "# RAdam, Lookahead, QHAdamW, AdamP\n",
        "# model.experiment(epochs=10)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOuzpMB9rsw8",
        "outputId": "e66a2932-c00e-4d2f-ca24-8ab8d4bfc98c"
      },
      "source": [
        "torch.tensor([1]).unsqueeze(0)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EiAtdkGtGltf",
        "outputId": "e78ae3ff-871b-4e97-c569-78b929c7a859"
      },
      "source": [
        "model.evaluate_performance(test_data)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Level</th>\n",
              "      <th>F1-Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B-a1_be_have_do_in_the_past</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B-a1_can</td>\n",
              "      <td>0.933333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B-a1_comparative_exept</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B-a1_comparative_long</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B-a1_comparative_short</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>B-a1_future_simple</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>B-a1_have_has_got</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>B-a1_past_simple_irreg</td>\n",
              "      <td>0.708333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>B-a1_past_simple_reg</td>\n",
              "      <td>0.727273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>B-a1_possesive_s_sing</td>\n",
              "      <td>0.709677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>B-a1_possessive_s_plurar</td>\n",
              "      <td>0.933333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>B-a1_present_continuous_act_rn</td>\n",
              "      <td>0.933333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>B-a1_present_simple_3d_pers</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>B-a1_present_simple_reg_act</td>\n",
              "      <td>0.821429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>B-a1_special_questions</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>B-a1_superlative_exept</td>\n",
              "      <td>0.736842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>B-a1_superlative_long</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>B-a1_superlative_short</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>B-a1_there_is_am_are</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>B-a1_there_was_were</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>B-a1_there_will_be</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>B-a1_to_be_future_will_be</td>\n",
              "      <td>0.923077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>B-a1_to_be_past_was_were</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>B-a1_to_be_present_is_am_are</td>\n",
              "      <td>0.736842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>B-a1_want_would_like_to</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>I-a1_can</td>\n",
              "      <td>0.864865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>I-a1_comparative_exept</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>I-a1_comparative_long</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>I-a1_comparative_short</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>I-a1_future_simple</td>\n",
              "      <td>0.846154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>I-a1_have_has_got</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>I-a1_past_simple_irreg</td>\n",
              "      <td>0.618182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>I-a1_past_simple_reg</td>\n",
              "      <td>0.705882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>I-a1_possesive_s_sing</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>I-a1_possessive_s_plurar</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>I-a1_present_continuous_act_rn</td>\n",
              "      <td>0.827586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>I-a1_present_simple_3d_pers</td>\n",
              "      <td>0.564103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>I-a1_present_simple_reg_act</td>\n",
              "      <td>0.758621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>I-a1_special_questions</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>I-a1_superlative_exept</td>\n",
              "      <td>0.909091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>I-a1_superlative_long</td>\n",
              "      <td>0.636364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>I-a1_superlative_short</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>I-a1_there_is_am_are</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>I-a1_there_was_were</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>I-a1_there_will_be</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>I-a1_to_be_future_will_be</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>I-a1_to_be_past_was_were</td>\n",
              "      <td>0.727273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>I-a1_to_be_present_is_am_are</td>\n",
              "      <td>0.813559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>I-a1_want_would_like_to</td>\n",
              "      <td>0.628571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>I-a1_be_have_do_in_the_past</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AVG_MICRO</td>\n",
              "      <td>0.770104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AVG_MACRO</td>\n",
              "      <td>0.664846</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             Level  F1-Score\n",
              "0      B-a1_be_have_do_in_the_past  0.000000\n",
              "1                         B-a1_can  0.933333\n",
              "2           B-a1_comparative_exept  0.600000\n",
              "3            B-a1_comparative_long  0.833333\n",
              "4           B-a1_comparative_short  0.750000\n",
              "5               B-a1_future_simple  0.666667\n",
              "6                B-a1_have_has_got  1.000000\n",
              "7           B-a1_past_simple_irreg  0.708333\n",
              "8             B-a1_past_simple_reg  0.727273\n",
              "9            B-a1_possesive_s_sing  0.709677\n",
              "10        B-a1_possessive_s_plurar  0.933333\n",
              "11  B-a1_present_continuous_act_rn  0.933333\n",
              "12     B-a1_present_simple_3d_pers  0.714286\n",
              "13     B-a1_present_simple_reg_act  0.821429\n",
              "14          B-a1_special_questions  0.000000\n",
              "15          B-a1_superlative_exept  0.736842\n",
              "16           B-a1_superlative_long  0.600000\n",
              "17          B-a1_superlative_short  0.857143\n",
              "18            B-a1_there_is_am_are  1.000000\n",
              "19             B-a1_there_was_were  1.000000\n",
              "20              B-a1_there_will_be  0.000000\n",
              "21       B-a1_to_be_future_will_be  0.923077\n",
              "22        B-a1_to_be_past_was_were  0.666667\n",
              "23    B-a1_to_be_present_is_am_are  0.736842\n",
              "24         B-a1_want_would_like_to  0.000000\n",
              "25                        I-a1_can  0.864865\n",
              "26          I-a1_comparative_exept  0.000000\n",
              "27           I-a1_comparative_long  0.833333\n",
              "28          I-a1_comparative_short  0.000000\n",
              "29              I-a1_future_simple  0.846154\n",
              "30               I-a1_have_has_got  1.000000\n",
              "31          I-a1_past_simple_irreg  0.618182\n",
              "32            I-a1_past_simple_reg  0.705882\n",
              "33           I-a1_possesive_s_sing  0.800000\n",
              "34        I-a1_possessive_s_plurar  0.857143\n",
              "35  I-a1_present_continuous_act_rn  0.827586\n",
              "36     I-a1_present_simple_3d_pers  0.564103\n",
              "37     I-a1_present_simple_reg_act  0.758621\n",
              "38          I-a1_special_questions  0.000000\n",
              "39          I-a1_superlative_exept  0.909091\n",
              "40           I-a1_superlative_long  0.636364\n",
              "41          I-a1_superlative_short  1.000000\n",
              "42            I-a1_there_is_am_are  1.000000\n",
              "43             I-a1_there_was_were  1.000000\n",
              "44              I-a1_there_will_be  0.000000\n",
              "45       I-a1_to_be_future_will_be  1.000000\n",
              "46        I-a1_to_be_past_was_were  0.727273\n",
              "47    I-a1_to_be_present_is_am_are  0.813559\n",
              "48         I-a1_want_would_like_to  0.628571\n",
              "49     I-a1_be_have_do_in_the_past  0.000000\n",
              "0                        AVG_MICRO  0.770104\n",
              "0                        AVG_MACRO  0.664846"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RepfsIqlDGQO",
        "outputId": "7abedf6f-b988-4f4b-88d9-779b0781bf15"
      },
      "source": [
        "# torch.save(model.network.state_dict(), \"./my_nerda/roberta-base-0.764-loss-0.266.pt\")\n",
        "model.network.load_state_dict(torch.load(\"./my_nerda/roberta-base-0.77-loss-0.278.pt\"))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vb-ySz53L3p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTlMk-feG4Yt"
      },
      "source": [
        "# torch.save(model.network.state_dict(), \"./my_nerda/roberta-base-0.77-loss-0.278.pt\")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81DtCEJN4qlx"
      },
      "source": [
        "sentences_orig = [\n",
        "         'DeepSpeed is a deep learning library on top of PyTorch that makes training models at extreme-scale efficient and easy for everyone.', \n",
        "         'DeepSpeed offers powerful training features for data scientists training on massive supercomputers as well as those training on low-end clusters or even on a single GPU.',\n",
        "         'There are other ways that I am using self - care to tend to my mental health.',\n",
        "         \"What's more, essential workers are risking their lives so that we can have our necessities.\",\n",
        "         'While all of this is happening, the luxury travel market is growing and becoming even more exclusive than it already was.',\n",
        "         \"Let's say you live in iowa and you have a bang coming on once a month.\",\n",
        "          \"The thing is, I might even like what he's saying and maybe even agree with him.\",\n",
        "         \"Sometimes his mouth moves like he's talking to someone, but there's no one else there.\",\n",
        "         \"He's just sitting there outside her house in normal civilian clothes, all alone.\",\n",
        "         \"He doesn't know where he's going; he just goes.\",\n",
        "         \"He's still smiling, looking at Sean with kind, knowing eyes.\",\n",
        "         \"He follows Joey into his apartment, past a living area where two other guys are watching TV.\",\n",
        "         \"Sean accidentally shoulders the elevator wall as he's walking out, but doesn't acknowledge it.\",\n",
        "         \"He feels comfortable giving away his address, whereas Sean would never dare give him his.\",\n",
        "         \"It's the same address from the police files, just two blocks away.\",\n",
        "         \"He's smiling in the picture, even though you're not supposed to do that for ID photos.\",\n",
        "         'When her friends asked her about it, she told them that she was having trouble with some \"horse syndicate\" people.',\n",
        "         \"In a letter addressed to her husband, Renee wrote that she was unhappy in her marriage and was contemplating getting a divorce.\",\n",
        "         \"Terry was coming toward me, a huge grin plastered on his face - as he pumped his legs on his unicycle.\",\n",
        "         \"We met at Piedmont Park, where Terry had suggested we could ride bikes.\",\n",
        "         \"What I had feared ended up coming true - my hair smelled like Terry's discount ham for weeks.\",\n",
        "         \"Perseverance has a large amount of data in its memory banks which it is gradually offloading to Earth.\",\n",
        "         \"Nasa is promising more in the next few days.\",\n",
        "         \"It shows the robot heading down to the ground on Thursday to make its landing.\",\n",
        "         \"It was acquired by the rocket cradle that placed the vehicle on the surface.\",\n",
        "         \"Perseverance has been put in a near-equatorial Martian crater known as Jezero where it will search for signs of past microbial life.\",\n",
        "         \"You can see the dust kicked up by the engines.\",\n",
        "         \"We're probably about 2m or so above the surface of Mars.\",\n",
        "         \"And then the curly electrical umbilical that is taking all of the electrical signals from the descent stage down to the computer inside the belly of the rover, the ones and zeros that represent this image.\",\n",
        "         \"Engineers report Perseverance to be in good health, as they gradually commission its systems.\",\n",
        "         \"Even now, with just this limited first release of pictures, there were fascinating rocks to discuss, she told reporters.\",\n",
        "         \"The $2.7bn (1.9bn) robot is the fifth rover to be put on Mars by Nasa.\",\n",
        "         \"As well as searching for signs of life, Perseverance's other key objective is to select and package rock samples that can be brought back to Earth laboratories by later missions.\",\n",
        "         ]\n",
        "sentences = [[str(i)for i in nlp(str(sent))] for sent in sentences_orig]\n",
        "predicts = model.predict(sentences)\n",
        "# sentences"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeQk8hgY4wL1"
      },
      "source": [
        "def get_entity_from_sent(sent, label):\n",
        "    prev_label = label[0][2:]\n",
        "    # sent = normal_nlp(str(sent))\n",
        "    sent = [str(token) for token in sent]\n",
        "    relu = lambda x: x if x > 0 else 0\n",
        "    accum = []\n",
        "    ent_len = 0\n",
        "    start = 0\n",
        "    for i, tok in enumerate(label):\n",
        "      tok = tok[2:]\n",
        "      ent_len += 1\n",
        "      if tok != label[relu(i-1)][2:]:\n",
        "        prev_ent = label[relu(i-1)][2:]\n",
        "        if ent_len > 1 and prev_ent != '':\n",
        "          accum.append({\n",
        "              'ent': prev_ent,\n",
        "              'start': relu(start),\n",
        "              'end': relu(i)\n",
        "              })\n",
        "        ent_len = 0\n",
        "        start = i\n",
        " \n",
        "    full_sent =  str(\" \".join(sent))\n",
        "    result = {\n",
        "          'text': full_sent,\n",
        "          'ents': [],\n",
        "          'title': None\n",
        "      }\n",
        "    for ent in accum:\n",
        "      sub_ent = \" \".join(sent[ent['start']:ent['end']])\n",
        "      start = full_sent.index(sub_ent)\n",
        "      end = start + len(sub_ent)\n",
        "      result['ents'].append(\n",
        "          {'start': start, 'end': end, 'label': ent['ent']}\n",
        "      )\n",
        "    return result"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0ONSBlSN43Tx",
        "outputId": "b9feb879-eec1-4a8d-da81-04784a9d7d55"
      },
      "source": [
        "for sent, pred in zip(sentences, predicts):\n",
        "  entities = get_entity_from_sent(sent, pred)\n",
        "  html = displacy.render(entities, style=\"ent\", manual=True, jupyter=True)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    DeepSpeed is\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_to_be_present_is_am_are</span>\n",
              "</mark>\n",
              " a deep learning library on top of PyTorch \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    that makes\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_simple_3d_pers</span>\n",
              "</mark>\n",
              " training models at extreme - scale efficient and easy for everyone .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    DeepSpeed offers\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_simple_3d_pers</span>\n",
              "</mark>\n",
              " powerful training features for data scientists training on massive supercomputers as well as those training on low - end clusters or even on a single GPU .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    There are\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_there_is_am_are</span>\n",
              "</mark>\n",
              " other ways that \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    I am using\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_continuous_act_rn</span>\n",
              "</mark>\n",
              " self - care to tend to my mental health .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    What 's\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_to_be_present_is_am_are</span>\n",
              "</mark>\n",
              " more , essential \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    workers are risking\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_continuous_act_rn</span>\n",
              "</mark>\n",
              " their lives so that \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    we can have\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_can</span>\n",
              "</mark>\n",
              " our necessities .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">While all of this \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    is happening\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_continuous_act_rn</span>\n",
              "</mark>\n",
              " , the luxury travel \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    market is growing\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_continuous_act_rn</span>\n",
              "</mark>\n",
              " and becoming even \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    more exclusive\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_comparative_long</span>\n",
              "</mark>\n",
              " than \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    it already was\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_to_be_past_was_were</span>\n",
              "</mark>\n",
              " .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Let 's say \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    you live\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_simple_reg_act</span>\n",
              "</mark>\n",
              " in iowa and \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    you have\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_simple_reg_act</span>\n",
              "</mark>\n",
              " a bang coming on once a month .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    The thing is\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_to_be_present_is_am_are</span>\n",
              "</mark>\n",
              " , I might even like what \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    he 's saying\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_continuous_act_rn</span>\n",
              "</mark>\n",
              " and maybe even agree with him .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Sometimes his \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    mouth moves\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_simple_3d_pers</span>\n",
              "</mark>\n",
              " like \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    he 's talking\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_continuous_act_rn</span>\n",
              "</mark>\n",
              " to someone , but \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    there 's\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_there_is_am_are</span>\n",
              "</mark>\n",
              " no one else there .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    He 's just sitting\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_continuous_act_rn</span>\n",
              "</mark>\n",
              " there outside her house in normal civilian clothes , all alone .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    He does n't know\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_simple_reg_act</span>\n",
              "</mark>\n",
              " where \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    he 's going\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_continuous_act_rn</span>\n",
              "</mark>\n",
              " ; \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    he just goes\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_simple_3d_pers</span>\n",
              "</mark>\n",
              " .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    He 's still smiling\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_continuous_act_rn</span>\n",
              "</mark>\n",
              " , looking at Sean with kind , knowing eyes .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    He follows\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_simple_3d_pers</span>\n",
              "</mark>\n",
              " Joey into his apartment , past a living area where two \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    other guys are watching\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_continuous_act_rn</span>\n",
              "</mark>\n",
              " TV .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Sean accidentally shoulders\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_simple_3d_pers</span>\n",
              "</mark>\n",
              " the elevator wall as \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    he 's walking\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_continuous_act_rn</span>\n",
              "</mark>\n",
              " out , but does \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    n't acknowledge\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_simple_reg_act</span>\n",
              "</mark>\n",
              " it .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    He feels\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_simple_3d_pers</span>\n",
              "</mark>\n",
              " comfortable giving away his address , whereas Sean would never dare give him his .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    It 's\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_to_be_present_is_am_are</span>\n",
              "</mark>\n",
              " the same address from the police files , just two blocks away .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    He 's smiling\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_continuous_act_rn</span>\n",
              "</mark>\n",
              " in the picture , even though you 're not supposed to do that for ID photos .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When her \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    friends asked\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_past_simple_reg</span>\n",
              "</mark>\n",
              " her about it , \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    she told\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_past_simple_irreg</span>\n",
              "</mark>\n",
              " them that she was having trouble with some &quot; horse syndicate &quot; people .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">In a letter addressed to her husband , \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Renee wrote\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_past_simple_irreg</span>\n",
              "</mark>\n",
              " that \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    she was\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_to_be_past_was_were</span>\n",
              "</mark>\n",
              " unhappy in her marriage and was contemplating getting a divorce .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Terry was coming toward me , a huge grin plastered on his face - as \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    he pumped\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_past_simple_reg</span>\n",
              "</mark>\n",
              " his legs on his unicycle .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    We met\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_past_simple_irreg</span>\n",
              "</mark>\n",
              " at Piedmont Park , where Terry had suggested we could ride bikes .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">What I had feared ended up coming true - my \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    hair smelled\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_past_simple_reg</span>\n",
              "</mark>\n",
              " like \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Terry 's\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_possesive_s_sing</span>\n",
              "</mark>\n",
              " discount ham for weeks .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Perseverance has\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_simple_3d_pers</span>\n",
              "</mark>\n",
              " a large amount of data in its memory banks which \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    it is gradually offloading\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_continuous_act_rn</span>\n",
              "</mark>\n",
              " to Earth .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Nasa is promising\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_continuous_act_rn</span>\n",
              "</mark>\n",
              " more in the next few days .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    It shows\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_simple_3d_pers</span>\n",
              "</mark>\n",
              " the robot heading down to the ground on Thursday to make its landing .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">It was acquired by the rocket cradle that placed the vehicle on the surface .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Perseverance has been put in a near - equatorial Martian crater known as Jezero where \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    it will search\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_future_simple</span>\n",
              "</mark>\n",
              " for signs of past microbial life .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    You can see\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_can</span>\n",
              "</mark>\n",
              " the dust kicked up by the engines .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    We 're\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_to_be_present_is_am_are</span>\n",
              "</mark>\n",
              " probably about 2 m or so above the surface of Mars .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">And then the curly electrical umbilical that \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    is taking\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_continuous_act_rn</span>\n",
              "</mark>\n",
              " all of the electrical signals from the descent stage down to the computer inside the belly of the rover , the ones and zeros \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    that represent\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_simple_reg_act</span>\n",
              "</mark>\n",
              " this image .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Engineers report\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_simple_reg_act</span>\n",
              "</mark>\n",
              " Perseverance to be in good health , as \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    they gradually commission\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_present_simple_reg_act</span>\n",
              "</mark>\n",
              " its systems .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Even now , with just this limited first release of pictures , \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    there were\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_there_was_were</span>\n",
              "</mark>\n",
              " fascinating rocks to discuss , \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    she told\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_past_simple_irreg</span>\n",
              "</mark>\n",
              " reporters .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The $ 2.7bn (  1.9bn ) robot is the fifth rover to be put on Mars by Nasa .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">As well as searching for signs of life , \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Perseverance 's\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">a1_possesive_s_sing</span>\n",
              "</mark>\n",
              " other key objective is to select and package rock samples that can be brought back to Earth laboratories by later missions .</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}