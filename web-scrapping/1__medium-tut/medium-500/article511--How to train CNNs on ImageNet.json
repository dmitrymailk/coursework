{"title": "How to train CNNs on ImageNet", "data": [{"type": "subtitle", "content": "A practical guide to using large image datasets for deep learning"}, {"type": "sentence", "content": "I\u2019ll go over how to get the ImageNet dataset, and train your convolutional neural net on it. I\u2019ve added some advice and learnings specific to training CNNs with PyTorch."}, {"type": "subtitle", "content": "Before you start"}, {"type": "sentence", "content": "If you haven\u2019t already, I recommend first trying to run your model on a sample image. When you\u2019re starting out, it\u2019s really tempting to jump to a big dataset like ImageNet to train your next state of the art model. However, I\u2019ve found it more effective to start small and slowly scale up your experiment. First, try an image to make sure your code works. Then, try a smaller dataset like CIFAR-10. Finally, try it out on ImageNet. Do sanity checks along the way and repeat them for each \u201cscale up\u201d."}, {"type": "sentence", "content": "Also, be aware of the differences in your model for the smaller image sizes of one dataset vs the other. For example, CIFAR-10 has only 32x32 size images which are smaller than ImageNet\u2019s variable image sizes. The average resolution of an ImageNet image is 469x387. They are usually cropped to 256x256 or 224x224 in your image preprocessing step."}, {"type": "sentence", "content": "In PyTorch, we don\u2019t define an input height or width like we would in TensorFlow, so it\u2019s your job to make sure output channel sizes along the way are appropriate in your network for a given input size. My advice is to be wary of how dimensionality reduction occurs from shallow to deeper filters in your network, especially as you change your dataset."}, {"type": "image", "content": "https://miro.medium.com/max/1700/0*El8wnxPDg35bmu2T.jpg"}, {"type": "sentence", "content": "In general, as you increase the input resolution to a new dataset, the early receptive field should also increase in size (via increasing kernel size or adding pooling layers)."}, {"type": "sentence", "content": "This is for two reasons:"}, {"type": "sentence", "content": "Both of these errors fail silently. These errors result in only an 8% decrease in top 1 accuracy when an ImageNet shaped ResNet is improperly applied to CIFAR-10. To correct this error, when moving from CIFAR-10 to ImageNet, the ResNet authors add an early max-pool layer, and use a larger initial kernel size (5x5 \u2192 7x7)."}, {"type": "sentence", "content": "I\u2019d really recommend reading this blog post by Andrej Karpathy for a deeper intuition of this art. I\u2019d also recommend this post by Tim Rocktaschel on advice for short term ML projects."}, {"type": "subtitle", "content": "Downloading ImageNet"}, {"type": "sentence", "content": "This is best done on a cloud environment. Unless you have access to a powerful GPU and a large SSD, I wouldn\u2019t recommend doing this locally."}, {"type": "sentence", "content": "Before doing any training, spin up a Google Colab instance or an AWS SageMaker instance to use a Jupyter Notebook to experiment with your model & visualise the data being passed in. Then when you want to train your model, I\u2019d recommend using a script and spinning up an EC2 instance with the AWS Deep Learning AMI. Attach an EBS instance to your EC2 with enough storage space for downloading & unzipping ImageNet. For 2012 ImageNet, the compressed download is 150GB. But you will need ~400GB since you need enough space to unzip the files, then delete the .tar afterwards. Using an EBS instance also means you can upgrade your EC2 without having to re-download the data."}, {"type": "sentence", "content": "Now to actually download ImageNet, the official instructions are to sign up as a researcher with your research institution here."}, {"type": "sentence", "content": "I don\u2019t think Stanford has been maintaining this for quite some time, as you\u2019ll never get the email invite. So, what I found is effective is to download ImageNet from Academic Torrents."}, {"type": "sentence", "content": "Search for ImageNet, get the desired magnet links, and use the CLI to download torrents with Transmission. Make sure your instance has internet access!"}, {"type": "sentence", "content": "Then setup your download directory"}, {"type": "sentence", "content": "And add your magnet link"}, {"type": "sentence", "content": "Find other important commands here."}, {"type": "sentence", "content": "Once you have downloaded the compressed files, we\u2019d like to extract them and put them in the correct folders so that they match what the PyTorch ImageFolder class expects as described in the documentation here."}, {"type": "sentence", "content": "Place ILSVRC2012_img_train.tar and ILSVRC2012_img_val.tar in the same folder as the following script to get the desired folders. Edit as necessary for your specific torrent."}, {"type": "sentence", "content": "I\u2019d also recommend throwing both .tar files onto a bucket in S3 so you can get them from there next time. Don\u2019t toss the uncompressed files since you pay for individual requests per object on S3."}, {"type": "subtitle", "content": "Setting up Data Loaders"}, {"type": "sentence", "content": "I\u2019d recommend setting up your usage of PyTorch\u2019s DataLoader and ImageFolder in a module titled with the dataset. I\u2019ve found that easy to help keep dataset specific augmentations in different files. Here\u2019s an example imagenet.py for use with ResNet. Set up your default batch size, your normalising transformation, and crop that is specific to this dataset. Perhaps in another file like cifar10.py you could have the dataset loader with settings specific to cifar-10 (with different batch size, normalisation, and crop)."}, {"type": "subtitle", "content": "Training with ImageNet"}, {"type": "sentence", "content": "I would not recommend training a model on a massive dataset like ImageNet or Sports1M in a Jupyter notebook. You may have timeouts, and your instance will disconnect from stdout which leads to you not seeing the progress your model is making either. A safer option is to ssh in and train with a script in a screen."}, {"type": "sentence", "content": "I would also recommend using neptune.ai to track progress in a neat visual dashboard. Some people use TensorBoard or TensorBoardX for pytorch, but I\u2019ve yet to try that out. I liked neptune.ai because it keeps my results around even after I\u2019ve closed the instances, and lets me easily compare experiments."}, {"type": "sentence", "content": "Now use your data loaders with your model, your choice of an optimiser, and your choice of loss to train on ImageNet. It\u2019ll look like some variation of the following pseudocode:"}, {"type": "sentence", "content": "This is only for training. Use this in a loop with a validation function to alternate training and scoring on the validation set in each epoch. For more examples on how to do this, look at the official PyTorch examples here."}, {"type": "sentence", "content": "Remember to have a look at the data before it goes in to your network at least once. This means actually visualising it. Here\u2019s a sample sanity check below to use to make sure everything is going well during preprocessing."}, {"type": "sentence", "content": "For completeness, I\u2019ve added some code above the sanity check to generate the denormalising transformation (to view the actual image without the effects of normalisation)."}, {"type": "sentence", "content": "Now have fun training & keep your sanity with sanity checks! \ud83d\ude04"}], "topic": "artificial-intelligence"}